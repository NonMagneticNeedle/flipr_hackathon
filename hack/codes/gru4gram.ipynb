{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gru4gram.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4cGn6c9m5ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_L5NldN2ouR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0314afb5-2a8d-419f-d912-6ab3134d3eaa"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive/')\n",
        "!cd \"/content/drive/My Drive/hack/\"\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwjBJomnsR6-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c00ea2ca-9e58-4ea0-e001-10807eac0696"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "print(tf.__version__)\n",
        "train_data =pd.read_excel('/content/drive/My Drive/hack/Test_dataset.xlsx','Put-Call_TS')\n",
        "train_data=train_data.rename(columns={'Put-Call Ratio':'aug10','Unnamed: 2':'aug11','Unnamed: 3':'aug12','Unnamed: 4':'aug13','Unnamed: 5':'aug14','Unnamed: 6':'aug15'})\n",
        "train_data=train_data.drop([0],axis=0)\n",
        "print(train_data.head())\n",
        "print(train_data.columns)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "  Stock Index aug10  aug11    aug12     aug13     aug14     aug15\n",
            "1      AC3235   0.8   0.66   0.7724  0.983224  0.901211  0.898368\n",
            "2      AC3236  0.86  0.732  0.85448   1.08664   1.01704   1.02926\n",
            "3      AC3237  0.93  0.816  0.95024    1.2073       NaN   1.18196\n",
            "4      AC3238  1.09  1.008  1.16912   1.48309   1.46106     1.531\n",
            "5      AC3239   NaN  1.104  1.27856   1.62099    1.6155   1.70552\n",
            "Index(['Stock Index', 'aug10', 'aug11', 'aug12', 'aug13', 'aug14', 'aug15'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIFsf1S34iAE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "637f19d2-c9b3-4a2a-ccbf-b2c4bc349fd8"
      },
      "source": [
        "#we dont std scale here since all the columns are of the same feature but will have different mean and std so will 16 aug have a different mean and std \n",
        "#so doesnt make sense to invese std scale using parameters of past days\n",
        "#and the values are already very small(0,2)\n",
        "train_data.fillna(-1,inplace=True)#fill in missing data \n",
        "\n",
        "all_cols=['Stock Index', 'aug10', 'aug11', 'aug12', 'aug13', 'aug14', 'aug15']\n",
        "train_cols = ['aug10', 'aug11', 'aug12', 'aug13', 'aug14']\n",
        "train_y_col = ['aug15']\n",
        "test_cols =['aug11', 'aug12', 'aug13', 'aug14', 'aug15']\n",
        "y=train_data[train_y_col]\n",
        "train = train_data[train_cols]\n",
        "test = train_data[test_cols]\n",
        "test_indx = train_data['Stock Index']\n",
        "\n",
        "\n",
        "print(train_data.columns)\n",
        "print(train.head())\n",
        "print(test.head())\n",
        "print(y.head())\n",
        "train = train.values\n",
        "test = test.values\n",
        "y=y.values\n",
        "print(test_indx.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Stock Index', 'aug10', 'aug11', 'aug12', 'aug13', 'aug14', 'aug15'], dtype='object')\n",
            "   aug10  aug11    aug12     aug13     aug14\n",
            "1   0.80  0.660  0.77240  0.983224  0.901211\n",
            "2   0.86  0.732  0.85448  1.086645  1.017042\n",
            "3   0.93  0.816  0.95024  1.207302 -1.000000\n",
            "4   1.09  1.008  1.16912  1.483091  1.461062\n",
            "5  -1.00  1.104  1.27856  1.620986  1.615504\n",
            "   aug11    aug12     aug13     aug14     aug15\n",
            "1  0.660  0.77240  0.983224  0.901211  0.898368\n",
            "2  0.732  0.85448  1.086645  1.017042  1.029258\n",
            "3  0.816  0.95024  1.207302 -1.000000  1.181962\n",
            "4  1.008  1.16912  1.483091  1.461062  1.531000\n",
            "5  1.104  1.27856  1.620986  1.615504  1.705519\n",
            "      aug15\n",
            "1  0.898368\n",
            "2  1.029258\n",
            "3  1.181962\n",
            "4  1.531000\n",
            "5  1.705519\n",
            "1    AC3235\n",
            "2    AC3236\n",
            "3    AC3237\n",
            "4    AC3238\n",
            "5    AC3239\n",
            "Name: Stock Index, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU8vtug-w1Pa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2e3106b4-4e90-4cf1-8ad4-3d8efb6a856b"
      },
      "source": [
        "print(train.shape,y.shape,test.shape)\n",
        "train = train.reshape(3331, 5,1)\n",
        "test = test.reshape(3331, 5,1)\n",
        "y = y.reshape(3331,1)\n",
        "print(train.shape,y.shape,test.shape)\n",
        "print(train[0],test[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3331, 5, 1) (3331, 1, 1) (3331, 5, 1)\n",
            "(3331, 5, 1) (3331, 1) (3331, 5, 1)\n",
            "[[0.8       ]\n",
            " [0.66      ]\n",
            " [0.7724    ]\n",
            " [0.983224  ]\n",
            " [0.90121088]] [[0.66      ]\n",
            " [0.7724    ]\n",
            " [0.983224  ]\n",
            " [0.90121088]\n",
            " [0.89836829]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUoHsvn7vJmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "733ea66c-48a2-4396-fb70-ae5b6edb038a"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense,Lambda,Dropout\n",
        "import numpy as np\n",
        "\n",
        "data_dim = 1\n",
        "timesteps = 5\n",
        "nb_classes = 1\n",
        "\n",
        "# expected input data shape: (batch_size, timesteps, data_dim)\n",
        "model = Sequential()\n",
        "model.add(GRU(64, return_sequences=True,\n",
        "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
        "model.add(Dropout(0.5))               \n",
        "model.add(GRU(32, return_sequences=False))  # returns a sequence of vectors of dimension 32\n",
        "#model.add(GRU(32))  # return a single vector of dimension 32\n",
        "model.add(Dropout(0.5))              \n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.add(Lambda(lambda x: x*2))# to get output in (0,2)\n",
        "model.compile(loss='mse',\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              metrics=['mse'])\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(train, y, train_size=0.8, random_state=1234)\n",
        "print(X_train.shape,y_train.shape)\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=64,epochs=1000,\n",
        "          validation_data=(X_validation, y_validation))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2664, 5, 1) (2664, 1)\n",
            "Train on 2664 samples, validate on 667 samples\n",
            "Epoch 1/1000\n",
            "2664/2664 [==============================] - 1s 462us/sample - loss: 0.4688 - mse: 0.4688 - val_loss: 0.4363 - val_mse: 0.4363\n",
            "Epoch 2/1000\n",
            "2664/2664 [==============================] - 0s 117us/sample - loss: 0.2934 - mse: 0.2934 - val_loss: 0.2762 - val_mse: 0.2762\n",
            "Epoch 3/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2474 - mse: 0.2474 - val_loss: 0.2785 - val_mse: 0.2785\n",
            "Epoch 4/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2459 - mse: 0.2459 - val_loss: 0.2742 - val_mse: 0.2742\n",
            "Epoch 5/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2477 - mse: 0.2477 - val_loss: 0.2744 - val_mse: 0.2744\n",
            "Epoch 6/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2478 - mse: 0.2478 - val_loss: 0.2746 - val_mse: 0.2746\n",
            "Epoch 7/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2452 - mse: 0.2452 - val_loss: 0.2730 - val_mse: 0.2730\n",
            "Epoch 8/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2461 - mse: 0.2461 - val_loss: 0.2778 - val_mse: 0.2778\n",
            "Epoch 9/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2450 - mse: 0.2450 - val_loss: 0.2729 - val_mse: 0.2729\n",
            "Epoch 10/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2407 - mse: 0.2407 - val_loss: 0.2730 - val_mse: 0.2730\n",
            "Epoch 11/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2407 - mse: 0.2407 - val_loss: 0.2724 - val_mse: 0.2724\n",
            "Epoch 12/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2419 - mse: 0.2419 - val_loss: 0.2742 - val_mse: 0.2742\n",
            "Epoch 13/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2418 - mse: 0.2418 - val_loss: 0.2719 - val_mse: 0.2719\n",
            "Epoch 14/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2425 - mse: 0.2425 - val_loss: 0.2725 - val_mse: 0.2725\n",
            "Epoch 15/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2387 - mse: 0.2387 - val_loss: 0.2708 - val_mse: 0.2708\n",
            "Epoch 16/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2388 - mse: 0.2388 - val_loss: 0.2722 - val_mse: 0.2722\n",
            "Epoch 17/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2404 - mse: 0.2404 - val_loss: 0.2725 - val_mse: 0.2725\n",
            "Epoch 18/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2433 - mse: 0.2433 - val_loss: 0.2736 - val_mse: 0.2736\n",
            "Epoch 19/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2420 - mse: 0.2420 - val_loss: 0.2746 - val_mse: 0.2746\n",
            "Epoch 20/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2358 - mse: 0.2358 - val_loss: 0.2720 - val_mse: 0.2720\n",
            "Epoch 21/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2390 - mse: 0.2390 - val_loss: 0.2817 - val_mse: 0.2817\n",
            "Epoch 22/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2388 - mse: 0.2388 - val_loss: 0.2694 - val_mse: 0.2694\n",
            "Epoch 23/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2407 - mse: 0.2407 - val_loss: 0.2792 - val_mse: 0.2792\n",
            "Epoch 24/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2429 - mse: 0.2429 - val_loss: 0.2764 - val_mse: 0.2764\n",
            "Epoch 25/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2423 - mse: 0.2423 - val_loss: 0.2750 - val_mse: 0.2750\n",
            "Epoch 26/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2392 - mse: 0.2392 - val_loss: 0.2767 - val_mse: 0.2767\n",
            "Epoch 27/1000\n",
            "2664/2664 [==============================] - 0s 136us/sample - loss: 0.2394 - mse: 0.2394 - val_loss: 0.2763 - val_mse: 0.2763\n",
            "Epoch 28/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2375 - mse: 0.2375 - val_loss: 0.2685 - val_mse: 0.2685\n",
            "Epoch 29/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2372 - mse: 0.2372 - val_loss: 0.2717 - val_mse: 0.2717\n",
            "Epoch 30/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2386 - mse: 0.2386 - val_loss: 0.2634 - val_mse: 0.2634\n",
            "Epoch 31/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2326 - mse: 0.2326 - val_loss: 0.2704 - val_mse: 0.2704\n",
            "Epoch 32/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2356 - mse: 0.2356 - val_loss: 0.2619 - val_mse: 0.2619\n",
            "Epoch 33/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2341 - mse: 0.2341 - val_loss: 0.2595 - val_mse: 0.2595\n",
            "Epoch 34/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2308 - mse: 0.2308 - val_loss: 0.2573 - val_mse: 0.2573\n",
            "Epoch 35/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2298 - mse: 0.2298 - val_loss: 0.2571 - val_mse: 0.2571\n",
            "Epoch 36/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2326 - mse: 0.2326 - val_loss: 0.2620 - val_mse: 0.2620\n",
            "Epoch 37/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2284 - mse: 0.2284 - val_loss: 0.2721 - val_mse: 0.2721\n",
            "Epoch 38/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2311 - mse: 0.2311 - val_loss: 0.2558 - val_mse: 0.2558\n",
            "Epoch 39/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2329 - mse: 0.2329 - val_loss: 0.2544 - val_mse: 0.2544\n",
            "Epoch 40/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2287 - mse: 0.2287 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 41/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2275 - mse: 0.2275 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 42/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2328 - mse: 0.2328 - val_loss: 0.2520 - val_mse: 0.2520\n",
            "Epoch 43/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2277 - mse: 0.2277 - val_loss: 0.2486 - val_mse: 0.2486\n",
            "Epoch 44/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2278 - mse: 0.2278 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 45/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2302 - mse: 0.2302 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 46/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2307 - mse: 0.2307 - val_loss: 0.2566 - val_mse: 0.2566\n",
            "Epoch 47/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2255 - mse: 0.2255 - val_loss: 0.2534 - val_mse: 0.2534\n",
            "Epoch 48/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2298 - mse: 0.2298 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 49/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2211 - mse: 0.2211 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 50/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2266 - mse: 0.2266 - val_loss: 0.2471 - val_mse: 0.2471\n",
            "Epoch 51/1000\n",
            "2664/2664 [==============================] - 0s 118us/sample - loss: 0.2232 - mse: 0.2232 - val_loss: 0.2657 - val_mse: 0.2657\n",
            "Epoch 52/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2265 - mse: 0.2265 - val_loss: 0.2532 - val_mse: 0.2532\n",
            "Epoch 53/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2249 - mse: 0.2249 - val_loss: 0.2464 - val_mse: 0.2464\n",
            "Epoch 54/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2210 - mse: 0.2210 - val_loss: 0.2442 - val_mse: 0.2442\n",
            "Epoch 55/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2230 - mse: 0.2230 - val_loss: 0.2450 - val_mse: 0.2450\n",
            "Epoch 56/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2231 - mse: 0.2231 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 57/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2236 - mse: 0.2236 - val_loss: 0.2439 - val_mse: 0.2439\n",
            "Epoch 58/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2276 - mse: 0.2276 - val_loss: 0.2445 - val_mse: 0.2445\n",
            "Epoch 59/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2191 - mse: 0.2191 - val_loss: 0.2481 - val_mse: 0.2481\n",
            "Epoch 60/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2209 - mse: 0.2209 - val_loss: 0.2533 - val_mse: 0.2533\n",
            "Epoch 61/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2255 - mse: 0.2255 - val_loss: 0.2453 - val_mse: 0.2453\n",
            "Epoch 62/1000\n",
            "2664/2664 [==============================] - 0s 143us/sample - loss: 0.2230 - mse: 0.2230 - val_loss: 0.2442 - val_mse: 0.2442\n",
            "Epoch 63/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2241 - mse: 0.2241 - val_loss: 0.2422 - val_mse: 0.2422\n",
            "Epoch 64/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2218 - mse: 0.2218 - val_loss: 0.2428 - val_mse: 0.2428\n",
            "Epoch 65/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2219 - mse: 0.2219 - val_loss: 0.2440 - val_mse: 0.2440\n",
            "Epoch 66/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2252 - mse: 0.2252 - val_loss: 0.2430 - val_mse: 0.2430\n",
            "Epoch 67/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2179 - mse: 0.2179 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 68/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2204 - mse: 0.2204 - val_loss: 0.2442 - val_mse: 0.2442\n",
            "Epoch 69/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2202 - mse: 0.2202 - val_loss: 0.2428 - val_mse: 0.2428\n",
            "Epoch 70/1000\n",
            "2664/2664 [==============================] - 0s 136us/sample - loss: 0.2213 - mse: 0.2213 - val_loss: 0.2450 - val_mse: 0.2450\n",
            "Epoch 71/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2188 - mse: 0.2188 - val_loss: 0.2555 - val_mse: 0.2555\n",
            "Epoch 72/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2212 - mse: 0.2212 - val_loss: 0.2486 - val_mse: 0.2486\n",
            "Epoch 73/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2227 - mse: 0.2227 - val_loss: 0.2446 - val_mse: 0.2446\n",
            "Epoch 74/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2189 - mse: 0.2189 - val_loss: 0.2572 - val_mse: 0.2572\n",
            "Epoch 75/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2207 - mse: 0.2207 - val_loss: 0.2458 - val_mse: 0.2458\n",
            "Epoch 76/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2218 - mse: 0.2218 - val_loss: 0.2468 - val_mse: 0.2468\n",
            "Epoch 77/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2248 - mse: 0.2248 - val_loss: 0.2436 - val_mse: 0.2436\n",
            "Epoch 78/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2196 - mse: 0.2196 - val_loss: 0.2472 - val_mse: 0.2472\n",
            "Epoch 79/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2172 - mse: 0.2172 - val_loss: 0.2433 - val_mse: 0.2433\n",
            "Epoch 80/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2231 - mse: 0.2231 - val_loss: 0.2536 - val_mse: 0.2536\n",
            "Epoch 81/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2210 - mse: 0.2210 - val_loss: 0.2524 - val_mse: 0.2524\n",
            "Epoch 82/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2225 - mse: 0.2225 - val_loss: 0.2541 - val_mse: 0.2541\n",
            "Epoch 83/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2226 - mse: 0.2226 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 84/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2159 - mse: 0.2159 - val_loss: 0.2459 - val_mse: 0.2459\n",
            "Epoch 85/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2248 - mse: 0.2248 - val_loss: 0.2431 - val_mse: 0.2431\n",
            "Epoch 86/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2184 - mse: 0.2184 - val_loss: 0.2454 - val_mse: 0.2454\n",
            "Epoch 87/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2186 - mse: 0.2186 - val_loss: 0.2461 - val_mse: 0.2461\n",
            "Epoch 88/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2190 - mse: 0.2190 - val_loss: 0.2459 - val_mse: 0.2459\n",
            "Epoch 89/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2183 - mse: 0.2183 - val_loss: 0.2431 - val_mse: 0.2431\n",
            "Epoch 90/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2178 - mse: 0.2178 - val_loss: 0.2430 - val_mse: 0.2430\n",
            "Epoch 91/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2204 - mse: 0.2204 - val_loss: 0.2450 - val_mse: 0.2450\n",
            "Epoch 92/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2183 - mse: 0.2183 - val_loss: 0.2436 - val_mse: 0.2436\n",
            "Epoch 93/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2199 - mse: 0.2199 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 94/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2196 - mse: 0.2196 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 95/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2193 - mse: 0.2193 - val_loss: 0.2434 - val_mse: 0.2434\n",
            "Epoch 96/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2193 - mse: 0.2193 - val_loss: 0.2542 - val_mse: 0.2542\n",
            "Epoch 97/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2232 - mse: 0.2232 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 98/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2181 - mse: 0.2181 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 99/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2183 - mse: 0.2183 - val_loss: 0.2486 - val_mse: 0.2486\n",
            "Epoch 100/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2193 - mse: 0.2193 - val_loss: 0.2462 - val_mse: 0.2462\n",
            "Epoch 101/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2182 - mse: 0.2182 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 102/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2193 - mse: 0.2193 - val_loss: 0.2446 - val_mse: 0.2446\n",
            "Epoch 103/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2197 - mse: 0.2197 - val_loss: 0.2466 - val_mse: 0.2466\n",
            "Epoch 104/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2193 - mse: 0.2193 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 105/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2189 - mse: 0.2189 - val_loss: 0.2467 - val_mse: 0.2467\n",
            "Epoch 106/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2165 - mse: 0.2165 - val_loss: 0.2512 - val_mse: 0.2512\n",
            "Epoch 107/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2185 - mse: 0.2185 - val_loss: 0.2447 - val_mse: 0.2447\n",
            "Epoch 108/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2195 - mse: 0.2195 - val_loss: 0.2470 - val_mse: 0.2470\n",
            "Epoch 109/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2219 - mse: 0.2219 - val_loss: 0.2508 - val_mse: 0.2508\n",
            "Epoch 110/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2196 - mse: 0.2196 - val_loss: 0.2440 - val_mse: 0.2440\n",
            "Epoch 111/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2187 - mse: 0.2187 - val_loss: 0.2552 - val_mse: 0.2552\n",
            "Epoch 112/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2194 - mse: 0.2194 - val_loss: 0.2463 - val_mse: 0.2463\n",
            "Epoch 113/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2471 - val_mse: 0.2471\n",
            "Epoch 114/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2173 - mse: 0.2173 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 115/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2166 - mse: 0.2166 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "Epoch 116/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2183 - mse: 0.2183 - val_loss: 0.2464 - val_mse: 0.2464\n",
            "Epoch 117/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2183 - mse: 0.2183 - val_loss: 0.2457 - val_mse: 0.2457\n",
            "Epoch 118/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2169 - mse: 0.2169 - val_loss: 0.2440 - val_mse: 0.2440\n",
            "Epoch 119/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2158 - mse: 0.2158 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 120/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2176 - mse: 0.2176 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 121/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2177 - mse: 0.2177 - val_loss: 0.2522 - val_mse: 0.2522\n",
            "Epoch 122/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2192 - mse: 0.2192 - val_loss: 0.2445 - val_mse: 0.2445\n",
            "Epoch 123/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2170 - mse: 0.2170 - val_loss: 0.2447 - val_mse: 0.2447\n",
            "Epoch 124/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2209 - mse: 0.2209 - val_loss: 0.2467 - val_mse: 0.2467\n",
            "Epoch 125/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2168 - mse: 0.2168 - val_loss: 0.2547 - val_mse: 0.2547\n",
            "Epoch 126/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2175 - mse: 0.2175 - val_loss: 0.2529 - val_mse: 0.2529\n",
            "Epoch 127/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2454 - val_mse: 0.2454\n",
            "Epoch 128/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2174 - mse: 0.2174 - val_loss: 0.2434 - val_mse: 0.2434\n",
            "Epoch 129/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2197 - mse: 0.2197 - val_loss: 0.2451 - val_mse: 0.2451\n",
            "Epoch 130/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2172 - mse: 0.2172 - val_loss: 0.2434 - val_mse: 0.2434\n",
            "Epoch 131/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2197 - mse: 0.2197 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 132/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2159 - mse: 0.2159 - val_loss: 0.2426 - val_mse: 0.2426\n",
            "Epoch 133/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2549 - val_mse: 0.2549\n",
            "Epoch 134/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2186 - mse: 0.2186 - val_loss: 0.2482 - val_mse: 0.2482\n",
            "Epoch 135/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2179 - mse: 0.2179 - val_loss: 0.2473 - val_mse: 0.2473\n",
            "Epoch 136/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2195 - mse: 0.2195 - val_loss: 0.2445 - val_mse: 0.2445\n",
            "Epoch 137/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2169 - mse: 0.2169 - val_loss: 0.2420 - val_mse: 0.2420\n",
            "Epoch 138/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2191 - mse: 0.2191 - val_loss: 0.2450 - val_mse: 0.2450\n",
            "Epoch 139/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2170 - mse: 0.2170 - val_loss: 0.2463 - val_mse: 0.2463\n",
            "Epoch 140/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2163 - mse: 0.2163 - val_loss: 0.2457 - val_mse: 0.2457\n",
            "Epoch 141/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2178 - mse: 0.2178 - val_loss: 0.2430 - val_mse: 0.2430\n",
            "Epoch 142/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2162 - mse: 0.2162 - val_loss: 0.2442 - val_mse: 0.2442\n",
            "Epoch 143/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2169 - mse: 0.2169 - val_loss: 0.2487 - val_mse: 0.2487\n",
            "Epoch 144/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2170 - mse: 0.2170 - val_loss: 0.2461 - val_mse: 0.2461\n",
            "Epoch 145/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2164 - mse: 0.2164 - val_loss: 0.2464 - val_mse: 0.2464\n",
            "Epoch 146/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2435 - val_mse: 0.2435\n",
            "Epoch 147/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2182 - mse: 0.2182 - val_loss: 0.2441 - val_mse: 0.2441\n",
            "Epoch 148/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2168 - mse: 0.2168 - val_loss: 0.2479 - val_mse: 0.2479\n",
            "Epoch 149/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2191 - mse: 0.2191 - val_loss: 0.2446 - val_mse: 0.2446\n",
            "Epoch 150/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2187 - mse: 0.2187 - val_loss: 0.2468 - val_mse: 0.2468\n",
            "Epoch 151/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2169 - mse: 0.2169 - val_loss: 0.2465 - val_mse: 0.2465\n",
            "Epoch 152/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2163 - mse: 0.2163 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 153/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2154 - mse: 0.2154 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 154/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2160 - mse: 0.2160 - val_loss: 0.2482 - val_mse: 0.2482\n",
            "Epoch 155/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2184 - mse: 0.2184 - val_loss: 0.2476 - val_mse: 0.2476\n",
            "Epoch 156/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2173 - mse: 0.2173 - val_loss: 0.2491 - val_mse: 0.2491\n",
            "Epoch 157/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2489 - val_mse: 0.2489\n",
            "Epoch 158/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2459 - val_mse: 0.2459\n",
            "Epoch 159/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2170 - mse: 0.2170 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 160/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2169 - mse: 0.2169 - val_loss: 0.2483 - val_mse: 0.2483\n",
            "Epoch 161/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2155 - mse: 0.2155 - val_loss: 0.2534 - val_mse: 0.2534\n",
            "Epoch 162/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2169 - mse: 0.2169 - val_loss: 0.2478 - val_mse: 0.2478\n",
            "Epoch 163/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2165 - mse: 0.2165 - val_loss: 0.2436 - val_mse: 0.2436\n",
            "Epoch 164/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2188 - mse: 0.2188 - val_loss: 0.2458 - val_mse: 0.2458\n",
            "Epoch 165/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2170 - mse: 0.2170 - val_loss: 0.2444 - val_mse: 0.2444\n",
            "Epoch 166/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2164 - mse: 0.2164 - val_loss: 0.2470 - val_mse: 0.2470\n",
            "Epoch 167/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2184 - mse: 0.2184 - val_loss: 0.2441 - val_mse: 0.2441\n",
            "Epoch 168/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2167 - mse: 0.2167 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 169/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2154 - mse: 0.2154 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 170/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2167 - mse: 0.2167 - val_loss: 0.2447 - val_mse: 0.2447\n",
            "Epoch 171/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2166 - mse: 0.2166 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 172/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2165 - mse: 0.2165 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 173/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2163 - mse: 0.2163 - val_loss: 0.2477 - val_mse: 0.2477\n",
            "Epoch 174/1000\n",
            "2664/2664 [==============================] - 0s 118us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2445 - val_mse: 0.2445\n",
            "Epoch 175/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2157 - mse: 0.2157 - val_loss: 0.2466 - val_mse: 0.2466\n",
            "Epoch 176/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2154 - mse: 0.2154 - val_loss: 0.2477 - val_mse: 0.2477\n",
            "Epoch 177/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2179 - mse: 0.2179 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 178/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2185 - mse: 0.2185 - val_loss: 0.2471 - val_mse: 0.2471\n",
            "Epoch 179/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2162 - mse: 0.2162 - val_loss: 0.2477 - val_mse: 0.2477\n",
            "Epoch 180/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2479 - val_mse: 0.2479\n",
            "Epoch 181/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2166 - mse: 0.2166 - val_loss: 0.2442 - val_mse: 0.2442\n",
            "Epoch 182/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2476 - val_mse: 0.2476\n",
            "Epoch 183/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 184/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2171 - mse: 0.2171 - val_loss: 0.2425 - val_mse: 0.2425\n",
            "Epoch 185/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2192 - mse: 0.2192 - val_loss: 0.2453 - val_mse: 0.2453\n",
            "Epoch 186/1000\n",
            "2664/2664 [==============================] - 0s 118us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 187/1000\n",
            "2664/2664 [==============================] - 0s 117us/sample - loss: 0.2162 - mse: 0.2162 - val_loss: 0.2489 - val_mse: 0.2489\n",
            "Epoch 188/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2155 - mse: 0.2155 - val_loss: 0.2478 - val_mse: 0.2478\n",
            "Epoch 189/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2173 - mse: 0.2173 - val_loss: 0.2444 - val_mse: 0.2444\n",
            "Epoch 190/1000\n",
            "2664/2664 [==============================] - 0s 117us/sample - loss: 0.2188 - mse: 0.2188 - val_loss: 0.2511 - val_mse: 0.2511\n",
            "Epoch 191/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2166 - mse: 0.2166 - val_loss: 0.2445 - val_mse: 0.2445\n",
            "Epoch 192/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2529 - val_mse: 0.2529\n",
            "Epoch 193/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2441 - val_mse: 0.2441\n",
            "Epoch 194/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 195/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 196/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2475 - val_mse: 0.2475\n",
            "Epoch 197/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2177 - mse: 0.2177 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 198/1000\n",
            "2664/2664 [==============================] - 0s 118us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2470 - val_mse: 0.2470\n",
            "Epoch 199/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2465 - val_mse: 0.2465\n",
            "Epoch 200/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2174 - mse: 0.2174 - val_loss: 0.2586 - val_mse: 0.2586\n",
            "Epoch 201/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2163 - mse: 0.2163 - val_loss: 0.2430 - val_mse: 0.2430\n",
            "Epoch 202/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2164 - mse: 0.2164 - val_loss: 0.2515 - val_mse: 0.2515\n",
            "Epoch 203/1000\n",
            "2664/2664 [==============================] - 0s 136us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2491 - val_mse: 0.2491\n",
            "Epoch 204/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2156 - mse: 0.2156 - val_loss: 0.2478 - val_mse: 0.2478\n",
            "Epoch 205/1000\n",
            "2664/2664 [==============================] - 0s 140us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2491 - val_mse: 0.2491\n",
            "Epoch 206/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 207/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2512 - val_mse: 0.2512\n",
            "Epoch 208/1000\n",
            "2664/2664 [==============================] - 0s 141us/sample - loss: 0.2172 - mse: 0.2172 - val_loss: 0.2448 - val_mse: 0.2448\n",
            "Epoch 209/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2165 - mse: 0.2165 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 210/1000\n",
            "2664/2664 [==============================] - 0s 139us/sample - loss: 0.2175 - mse: 0.2175 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 211/1000\n",
            "2664/2664 [==============================] - 0s 140us/sample - loss: 0.2181 - mse: 0.2181 - val_loss: 0.2459 - val_mse: 0.2459\n",
            "Epoch 212/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2466 - val_mse: 0.2466\n",
            "Epoch 213/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 214/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2175 - mse: 0.2175 - val_loss: 0.2464 - val_mse: 0.2464\n",
            "Epoch 215/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2447 - val_mse: 0.2447\n",
            "Epoch 216/1000\n",
            "2664/2664 [==============================] - 0s 138us/sample - loss: 0.2162 - mse: 0.2162 - val_loss: 0.2559 - val_mse: 0.2559\n",
            "Epoch 217/1000\n",
            "2664/2664 [==============================] - 0s 136us/sample - loss: 0.2179 - mse: 0.2179 - val_loss: 0.2538 - val_mse: 0.2538\n",
            "Epoch 218/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2447 - val_mse: 0.2447\n",
            "Epoch 219/1000\n",
            "2664/2664 [==============================] - 0s 138us/sample - loss: 0.2191 - mse: 0.2191 - val_loss: 0.2593 - val_mse: 0.2593\n",
            "Epoch 220/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 221/1000\n",
            "2664/2664 [==============================] - 0s 140us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2481 - val_mse: 0.2481\n",
            "Epoch 222/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2491 - val_mse: 0.2491\n",
            "Epoch 223/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2457 - val_mse: 0.2457\n",
            "Epoch 224/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2187 - mse: 0.2187 - val_loss: 0.2467 - val_mse: 0.2467\n",
            "Epoch 225/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2575 - val_mse: 0.2575\n",
            "Epoch 226/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2160 - mse: 0.2160 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 227/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 228/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2159 - mse: 0.2159 - val_loss: 0.2472 - val_mse: 0.2472\n",
            "Epoch 229/1000\n",
            "2664/2664 [==============================] - 0s 136us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2466 - val_mse: 0.2466\n",
            "Epoch 230/1000\n",
            "2664/2664 [==============================] - 0s 140us/sample - loss: 0.2172 - mse: 0.2172 - val_loss: 0.2420 - val_mse: 0.2420\n",
            "Epoch 231/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2165 - mse: 0.2165 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 232/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2451 - val_mse: 0.2451\n",
            "Epoch 233/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2550 - val_mse: 0.2550\n",
            "Epoch 234/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2156 - mse: 0.2156 - val_loss: 0.2451 - val_mse: 0.2451\n",
            "Epoch 235/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2481 - val_mse: 0.2481\n",
            "Epoch 236/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2577 - val_mse: 0.2577\n",
            "Epoch 237/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2170 - mse: 0.2170 - val_loss: 0.2482 - val_mse: 0.2482\n",
            "Epoch 238/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2160 - mse: 0.2160 - val_loss: 0.2434 - val_mse: 0.2434\n",
            "Epoch 239/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2155 - mse: 0.2155 - val_loss: 0.2520 - val_mse: 0.2520\n",
            "Epoch 240/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2160 - mse: 0.2160 - val_loss: 0.2451 - val_mse: 0.2451\n",
            "Epoch 241/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2429 - val_mse: 0.2429\n",
            "Epoch 242/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2155 - mse: 0.2155 - val_loss: 0.2438 - val_mse: 0.2438\n",
            "Epoch 243/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "Epoch 244/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2157 - mse: 0.2157 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 245/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2170 - mse: 0.2170 - val_loss: 0.2463 - val_mse: 0.2463\n",
            "Epoch 246/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2158 - mse: 0.2158 - val_loss: 0.2480 - val_mse: 0.2480\n",
            "Epoch 247/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 248/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2171 - mse: 0.2171 - val_loss: 0.2523 - val_mse: 0.2523\n",
            "Epoch 249/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2171 - mse: 0.2171 - val_loss: 0.2472 - val_mse: 0.2472\n",
            "Epoch 250/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2179 - mse: 0.2179 - val_loss: 0.2482 - val_mse: 0.2482\n",
            "Epoch 251/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2464 - val_mse: 0.2464\n",
            "Epoch 252/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2461 - val_mse: 0.2461\n",
            "Epoch 253/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2141 - mse: 0.2141 - val_loss: 0.2481 - val_mse: 0.2481\n",
            "Epoch 254/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2159 - mse: 0.2159 - val_loss: 0.2478 - val_mse: 0.2478\n",
            "Epoch 255/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 256/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2153 - mse: 0.2153 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 257/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2478 - val_mse: 0.2478\n",
            "Epoch 258/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2471 - val_mse: 0.2471\n",
            "Epoch 259/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2450 - val_mse: 0.2450\n",
            "Epoch 260/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2160 - mse: 0.2160 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 261/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2167 - mse: 0.2167 - val_loss: 0.2462 - val_mse: 0.2462\n",
            "Epoch 262/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2449 - val_mse: 0.2449\n",
            "Epoch 263/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2471 - val_mse: 0.2471\n",
            "Epoch 264/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2448 - val_mse: 0.2448\n",
            "Epoch 265/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2442 - val_mse: 0.2442\n",
            "Epoch 266/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2153 - mse: 0.2153 - val_loss: 0.2452 - val_mse: 0.2452\n",
            "Epoch 267/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2430 - val_mse: 0.2430\n",
            "Epoch 268/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2476 - val_mse: 0.2476\n",
            "Epoch 269/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 270/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2154 - mse: 0.2154 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 271/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2202 - mse: 0.2202 - val_loss: 0.2453 - val_mse: 0.2453\n",
            "Epoch 272/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 273/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2207 - mse: 0.2207 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 274/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2428 - val_mse: 0.2428\n",
            "Epoch 275/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2475 - val_mse: 0.2475\n",
            "Epoch 276/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2458 - val_mse: 0.2458\n",
            "Epoch 277/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 278/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2155 - mse: 0.2155 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 279/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2156 - mse: 0.2156 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 280/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2155 - mse: 0.2155 - val_loss: 0.2434 - val_mse: 0.2434\n",
            "Epoch 281/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 282/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2162 - mse: 0.2162 - val_loss: 0.2452 - val_mse: 0.2452\n",
            "Epoch 283/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2180 - mse: 0.2180 - val_loss: 0.2420 - val_mse: 0.2420\n",
            "Epoch 284/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2167 - mse: 0.2167 - val_loss: 0.2441 - val_mse: 0.2441\n",
            "Epoch 285/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2159 - mse: 0.2159 - val_loss: 0.2476 - val_mse: 0.2476\n",
            "Epoch 286/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2182 - mse: 0.2182 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "Epoch 287/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2442 - val_mse: 0.2442\n",
            "Epoch 288/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2444 - val_mse: 0.2444\n",
            "Epoch 289/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2523 - val_mse: 0.2523\n",
            "Epoch 290/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2159 - mse: 0.2159 - val_loss: 0.2471 - val_mse: 0.2471\n",
            "Epoch 291/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2435 - val_mse: 0.2435\n",
            "Epoch 292/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2481 - val_mse: 0.2481\n",
            "Epoch 293/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2136 - mse: 0.2136 - val_loss: 0.2522 - val_mse: 0.2522\n",
            "Epoch 294/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 295/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2186 - mse: 0.2186 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 296/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2468 - val_mse: 0.2468\n",
            "Epoch 297/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2468 - val_mse: 0.2468\n",
            "Epoch 298/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2168 - mse: 0.2168 - val_loss: 0.2515 - val_mse: 0.2515\n",
            "Epoch 299/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2452 - val_mse: 0.2452\n",
            "Epoch 300/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2454 - val_mse: 0.2454\n",
            "Epoch 301/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2457 - val_mse: 0.2457\n",
            "Epoch 302/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2460 - val_mse: 0.2460\n",
            "Epoch 303/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2460 - val_mse: 0.2460\n",
            "Epoch 304/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2453 - val_mse: 0.2453\n",
            "Epoch 305/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2459 - val_mse: 0.2459\n",
            "Epoch 306/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2184 - mse: 0.2184 - val_loss: 0.2470 - val_mse: 0.2470\n",
            "Epoch 307/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "Epoch 308/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2455 - val_mse: 0.2455\n",
            "Epoch 309/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2476 - val_mse: 0.2476\n",
            "Epoch 310/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 311/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2620 - val_mse: 0.2620\n",
            "Epoch 312/1000\n",
            "2664/2664 [==============================] - 0s 118us/sample - loss: 0.2162 - mse: 0.2162 - val_loss: 0.2465 - val_mse: 0.2465\n",
            "Epoch 313/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2509 - val_mse: 0.2509\n",
            "Epoch 314/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2164 - mse: 0.2164 - val_loss: 0.2487 - val_mse: 0.2487\n",
            "Epoch 315/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 316/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2555 - val_mse: 0.2555\n",
            "Epoch 317/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2172 - mse: 0.2172 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 318/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2470 - val_mse: 0.2470\n",
            "Epoch 319/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2450 - val_mse: 0.2450\n",
            "Epoch 320/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2448 - val_mse: 0.2448\n",
            "Epoch 321/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2171 - mse: 0.2171 - val_loss: 0.2531 - val_mse: 0.2531\n",
            "Epoch 322/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2162 - mse: 0.2162 - val_loss: 0.2460 - val_mse: 0.2460\n",
            "Epoch 323/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2457 - val_mse: 0.2457\n",
            "Epoch 324/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2455 - val_mse: 0.2455\n",
            "Epoch 325/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2524 - val_mse: 0.2524\n",
            "Epoch 326/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 327/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2513 - val_mse: 0.2513\n",
            "Epoch 328/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 329/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2154 - mse: 0.2154 - val_loss: 0.2539 - val_mse: 0.2539\n",
            "Epoch 330/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2467 - val_mse: 0.2467\n",
            "Epoch 331/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2450 - val_mse: 0.2450\n",
            "Epoch 332/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2475 - val_mse: 0.2475\n",
            "Epoch 333/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 334/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2460 - val_mse: 0.2460\n",
            "Epoch 335/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2479 - val_mse: 0.2479\n",
            "Epoch 336/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2162 - mse: 0.2162 - val_loss: 0.2489 - val_mse: 0.2489\n",
            "Epoch 337/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2185 - mse: 0.2185 - val_loss: 0.2491 - val_mse: 0.2491\n",
            "Epoch 338/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2452 - val_mse: 0.2452\n",
            "Epoch 339/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2158 - mse: 0.2158 - val_loss: 0.2559 - val_mse: 0.2559\n",
            "Epoch 340/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2167 - mse: 0.2167 - val_loss: 0.2552 - val_mse: 0.2552\n",
            "Epoch 341/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2184 - mse: 0.2184 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 342/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2174 - mse: 0.2174 - val_loss: 0.2552 - val_mse: 0.2552\n",
            "Epoch 343/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2556 - val_mse: 0.2556\n",
            "Epoch 344/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2175 - mse: 0.2175 - val_loss: 0.2438 - val_mse: 0.2438\n",
            "Epoch 345/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2489 - val_mse: 0.2489\n",
            "Epoch 346/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2442 - val_mse: 0.2442\n",
            "Epoch 347/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2166 - mse: 0.2166 - val_loss: 0.2464 - val_mse: 0.2464\n",
            "Epoch 348/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2453 - val_mse: 0.2453\n",
            "Epoch 349/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2473 - val_mse: 0.2473\n",
            "Epoch 350/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 351/1000\n",
            "2664/2664 [==============================] - 0s 118us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2548 - val_mse: 0.2548\n",
            "Epoch 352/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2572 - val_mse: 0.2572\n",
            "Epoch 353/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2181 - mse: 0.2181 - val_loss: 0.2535 - val_mse: 0.2535\n",
            "Epoch 354/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2452 - val_mse: 0.2452\n",
            "Epoch 355/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2531 - val_mse: 0.2531\n",
            "Epoch 356/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2438 - val_mse: 0.2438\n",
            "Epoch 357/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2155 - mse: 0.2155 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 358/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2435 - val_mse: 0.2435\n",
            "Epoch 359/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 360/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2450 - val_mse: 0.2450\n",
            "Epoch 361/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 362/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2463 - val_mse: 0.2463\n",
            "Epoch 363/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2162 - mse: 0.2162 - val_loss: 0.2551 - val_mse: 0.2551\n",
            "Epoch 364/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 365/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2482 - val_mse: 0.2482\n",
            "Epoch 366/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2119 - mse: 0.2119 - val_loss: 0.2446 - val_mse: 0.2446\n",
            "Epoch 367/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2545 - val_mse: 0.2545\n",
            "Epoch 368/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 369/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 370/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2488 - val_mse: 0.2488\n",
            "Epoch 371/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 372/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2136 - mse: 0.2136 - val_loss: 0.2546 - val_mse: 0.2546\n",
            "Epoch 373/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2186 - mse: 0.2186 - val_loss: 0.2580 - val_mse: 0.2580\n",
            "Epoch 374/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2473 - val_mse: 0.2473\n",
            "Epoch 375/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2479 - val_mse: 0.2479\n",
            "Epoch 376/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2441 - val_mse: 0.2441\n",
            "Epoch 377/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 378/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 379/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2178 - mse: 0.2178 - val_loss: 0.2530 - val_mse: 0.2530\n",
            "Epoch 380/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2466 - val_mse: 0.2466\n",
            "Epoch 381/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 382/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 383/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2459 - val_mse: 0.2459\n",
            "Epoch 384/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2574 - val_mse: 0.2574\n",
            "Epoch 385/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2464 - val_mse: 0.2464\n",
            "Epoch 386/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 387/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2439 - val_mse: 0.2439\n",
            "Epoch 388/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2174 - mse: 0.2174 - val_loss: 0.2512 - val_mse: 0.2512\n",
            "Epoch 389/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2453 - val_mse: 0.2453\n",
            "Epoch 390/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2171 - mse: 0.2171 - val_loss: 0.2486 - val_mse: 0.2486\n",
            "Epoch 391/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2488 - val_mse: 0.2488\n",
            "Epoch 392/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 393/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2455 - val_mse: 0.2455\n",
            "Epoch 394/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2630 - val_mse: 0.2630\n",
            "Epoch 395/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2530 - val_mse: 0.2530\n",
            "Epoch 396/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2462 - val_mse: 0.2462\n",
            "Epoch 397/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2452 - val_mse: 0.2452\n",
            "Epoch 398/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2448 - val_mse: 0.2448\n",
            "Epoch 399/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "Epoch 400/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2173 - mse: 0.2173 - val_loss: 0.2526 - val_mse: 0.2526\n",
            "Epoch 401/1000\n",
            "2664/2664 [==============================] - 0s 140us/sample - loss: 0.2153 - mse: 0.2153 - val_loss: 0.2472 - val_mse: 0.2472\n",
            "Epoch 402/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2136 - mse: 0.2136 - val_loss: 0.2475 - val_mse: 0.2475\n",
            "Epoch 403/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2487 - val_mse: 0.2487\n",
            "Epoch 404/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 405/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2483 - val_mse: 0.2483\n",
            "Epoch 406/1000\n",
            "2664/2664 [==============================] - 0s 136us/sample - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2562 - val_mse: 0.2562\n",
            "Epoch 407/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2154 - mse: 0.2154 - val_loss: 0.2489 - val_mse: 0.2489\n",
            "Epoch 408/1000\n",
            "2664/2664 [==============================] - 0s 136us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2537 - val_mse: 0.2537\n",
            "Epoch 409/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2483 - val_mse: 0.2483\n",
            "Epoch 410/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2164 - mse: 0.2164 - val_loss: 0.2451 - val_mse: 0.2451\n",
            "Epoch 411/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2467 - val_mse: 0.2467\n",
            "Epoch 412/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2460 - val_mse: 0.2460\n",
            "Epoch 413/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2167 - mse: 0.2167 - val_loss: 0.2479 - val_mse: 0.2479\n",
            "Epoch 414/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2444 - val_mse: 0.2444\n",
            "Epoch 415/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2453 - val_mse: 0.2453\n",
            "Epoch 416/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2168 - mse: 0.2168 - val_loss: 0.2514 - val_mse: 0.2514\n",
            "Epoch 417/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2489 - val_mse: 0.2489\n",
            "Epoch 418/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2473 - val_mse: 0.2473\n",
            "Epoch 419/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2594 - val_mse: 0.2594\n",
            "Epoch 420/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2462 - val_mse: 0.2462\n",
            "Epoch 421/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2455 - val_mse: 0.2455\n",
            "Epoch 422/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2529 - val_mse: 0.2529\n",
            "Epoch 423/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2514 - val_mse: 0.2514\n",
            "Epoch 424/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2158 - mse: 0.2158 - val_loss: 0.2466 - val_mse: 0.2466\n",
            "Epoch 425/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2462 - val_mse: 0.2462\n",
            "Epoch 426/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2130 - mse: 0.2130 - val_loss: 0.2596 - val_mse: 0.2596\n",
            "Epoch 427/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 428/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2159 - mse: 0.2159 - val_loss: 0.2472 - val_mse: 0.2472\n",
            "Epoch 429/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 430/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2463 - val_mse: 0.2463\n",
            "Epoch 431/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2147 - mse: 0.2147 - val_loss: 0.2467 - val_mse: 0.2467\n",
            "Epoch 432/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2448 - val_mse: 0.2448\n",
            "Epoch 433/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2518 - val_mse: 0.2518\n",
            "Epoch 434/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2463 - val_mse: 0.2463\n",
            "Epoch 435/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2481 - val_mse: 0.2481\n",
            "Epoch 436/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2477 - val_mse: 0.2477\n",
            "Epoch 437/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2470 - val_mse: 0.2470\n",
            "Epoch 438/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2487 - val_mse: 0.2487\n",
            "Epoch 439/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2119 - mse: 0.2119 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 440/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2554 - val_mse: 0.2554\n",
            "Epoch 441/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2178 - mse: 0.2178 - val_loss: 0.2515 - val_mse: 0.2515\n",
            "Epoch 442/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 443/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2529 - val_mse: 0.2529\n",
            "Epoch 444/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2163 - mse: 0.2163 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 445/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2541 - val_mse: 0.2541\n",
            "Epoch 446/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 447/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2492 - val_mse: 0.2492\n",
            "Epoch 448/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 449/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2153 - mse: 0.2153 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 450/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2514 - val_mse: 0.2514\n",
            "Epoch 451/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2472 - val_mse: 0.2472\n",
            "Epoch 452/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2111 - mse: 0.2111 - val_loss: 0.2480 - val_mse: 0.2480\n",
            "Epoch 453/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 454/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2466 - val_mse: 0.2466\n",
            "Epoch 455/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2441 - val_mse: 0.2441\n",
            "Epoch 456/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 457/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2515 - val_mse: 0.2515\n",
            "Epoch 458/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2447 - val_mse: 0.2447\n",
            "Epoch 459/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2447 - val_mse: 0.2447\n",
            "Epoch 460/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 461/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 462/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2136 - mse: 0.2136 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "Epoch 463/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2092 - mse: 0.2092 - val_loss: 0.2470 - val_mse: 0.2470\n",
            "Epoch 464/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2487 - val_mse: 0.2487\n",
            "Epoch 465/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2460 - val_mse: 0.2460\n",
            "Epoch 466/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2540 - val_mse: 0.2540\n",
            "Epoch 467/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2105 - mse: 0.2105 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "Epoch 468/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2598 - val_mse: 0.2598\n",
            "Epoch 469/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2508 - val_mse: 0.2508\n",
            "Epoch 470/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2508 - val_mse: 0.2508\n",
            "Epoch 471/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2561 - val_mse: 0.2561\n",
            "Epoch 472/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2550 - val_mse: 0.2550\n",
            "Epoch 473/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2494 - val_mse: 0.2494\n",
            "Epoch 474/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2552 - val_mse: 0.2552\n",
            "Epoch 475/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2512 - val_mse: 0.2512\n",
            "Epoch 476/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2107 - mse: 0.2107 - val_loss: 0.2518 - val_mse: 0.2518\n",
            "Epoch 477/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2155 - mse: 0.2155 - val_loss: 0.2478 - val_mse: 0.2478\n",
            "Epoch 478/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2529 - val_mse: 0.2529\n",
            "Epoch 479/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2111 - mse: 0.2111 - val_loss: 0.2576 - val_mse: 0.2576\n",
            "Epoch 480/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2157 - mse: 0.2157 - val_loss: 0.2515 - val_mse: 0.2515\n",
            "Epoch 481/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2118 - mse: 0.2118 - val_loss: 0.2540 - val_mse: 0.2540\n",
            "Epoch 482/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2147 - mse: 0.2147 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 483/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2475 - val_mse: 0.2475\n",
            "Epoch 484/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2103 - mse: 0.2103 - val_loss: 0.2471 - val_mse: 0.2471\n",
            "Epoch 485/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2164 - mse: 0.2164 - val_loss: 0.2577 - val_mse: 0.2577\n",
            "Epoch 486/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2521 - val_mse: 0.2521\n",
            "Epoch 487/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 488/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2102 - mse: 0.2102 - val_loss: 0.2518 - val_mse: 0.2518\n",
            "Epoch 489/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2105 - mse: 0.2105 - val_loss: 0.2515 - val_mse: 0.2515\n",
            "Epoch 490/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2523 - val_mse: 0.2523\n",
            "Epoch 491/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 492/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "Epoch 493/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 494/1000\n",
            "2664/2664 [==============================] - 0s 136us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2470 - val_mse: 0.2470\n",
            "Epoch 495/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2476 - val_mse: 0.2476\n",
            "Epoch 496/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2486 - val_mse: 0.2486\n",
            "Epoch 497/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 498/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2170 - mse: 0.2170 - val_loss: 0.2477 - val_mse: 0.2477\n",
            "Epoch 499/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2557 - val_mse: 0.2557\n",
            "Epoch 500/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 501/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 502/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2464 - val_mse: 0.2464\n",
            "Epoch 503/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2102 - mse: 0.2102 - val_loss: 0.2554 - val_mse: 0.2554\n",
            "Epoch 504/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 505/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2486 - val_mse: 0.2486\n",
            "Epoch 506/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2473 - val_mse: 0.2473\n",
            "Epoch 507/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2141 - mse: 0.2141 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 508/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2591 - val_mse: 0.2591\n",
            "Epoch 509/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2487 - val_mse: 0.2487\n",
            "Epoch 510/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2550 - val_mse: 0.2550\n",
            "Epoch 511/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 512/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2562 - val_mse: 0.2562\n",
            "Epoch 513/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2158 - mse: 0.2158 - val_loss: 0.2542 - val_mse: 0.2542\n",
            "Epoch 514/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2130 - mse: 0.2130 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 515/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2452 - val_mse: 0.2452\n",
            "Epoch 516/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2483 - val_mse: 0.2483\n",
            "Epoch 517/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 518/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2100 - mse: 0.2100 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 519/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 520/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2107 - mse: 0.2107 - val_loss: 0.2530 - val_mse: 0.2530\n",
            "Epoch 521/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2141 - mse: 0.2141 - val_loss: 0.2520 - val_mse: 0.2520\n",
            "Epoch 522/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2492 - val_mse: 0.2492\n",
            "Epoch 523/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2115 - mse: 0.2115 - val_loss: 0.2462 - val_mse: 0.2462\n",
            "Epoch 524/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 525/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 526/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2467 - val_mse: 0.2467\n",
            "Epoch 527/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2482 - val_mse: 0.2482\n",
            "Epoch 528/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2095 - mse: 0.2095 - val_loss: 0.2547 - val_mse: 0.2547\n",
            "Epoch 529/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2471 - val_mse: 0.2471\n",
            "Epoch 530/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2468 - val_mse: 0.2468\n",
            "Epoch 531/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2113 - mse: 0.2113 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 532/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2460 - val_mse: 0.2460\n",
            "Epoch 533/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2157 - mse: 0.2157 - val_loss: 0.2540 - val_mse: 0.2540\n",
            "Epoch 534/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2523 - val_mse: 0.2523\n",
            "Epoch 535/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 536/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2151 - mse: 0.2151 - val_loss: 0.2512 - val_mse: 0.2512\n",
            "Epoch 537/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 538/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 539/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2157 - mse: 0.2157 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 540/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2511 - val_mse: 0.2511\n",
            "Epoch 541/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2094 - mse: 0.2094 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 542/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2458 - val_mse: 0.2458\n",
            "Epoch 543/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2142 - mse: 0.2142 - val_loss: 0.2476 - val_mse: 0.2476\n",
            "Epoch 544/1000\n",
            "2664/2664 [==============================] - 0s 139us/sample - loss: 0.2153 - mse: 0.2153 - val_loss: 0.2494 - val_mse: 0.2494\n",
            "Epoch 545/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2163 - mse: 0.2163 - val_loss: 0.2519 - val_mse: 0.2519\n",
            "Epoch 546/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 547/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 548/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2119 - mse: 0.2119 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 549/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 550/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 551/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2481 - val_mse: 0.2481\n",
            "Epoch 552/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2099 - mse: 0.2099 - val_loss: 0.2528 - val_mse: 0.2528\n",
            "Epoch 553/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2518 - val_mse: 0.2518\n",
            "Epoch 554/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2486 - val_mse: 0.2486\n",
            "Epoch 555/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "Epoch 556/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 557/1000\n",
            "2664/2664 [==============================] - 0s 139us/sample - loss: 0.2105 - mse: 0.2105 - val_loss: 0.2539 - val_mse: 0.2539\n",
            "Epoch 558/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2466 - val_mse: 0.2466\n",
            "Epoch 559/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2562 - val_mse: 0.2562\n",
            "Epoch 560/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2494 - val_mse: 0.2494\n",
            "Epoch 561/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2166 - mse: 0.2166 - val_loss: 0.2528 - val_mse: 0.2528\n",
            "Epoch 562/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2525 - val_mse: 0.2525\n",
            "Epoch 563/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2561 - val_mse: 0.2561\n",
            "Epoch 564/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2552 - val_mse: 0.2552\n",
            "Epoch 565/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2534 - val_mse: 0.2534\n",
            "Epoch 566/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 567/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2119 - mse: 0.2119 - val_loss: 0.2531 - val_mse: 0.2531\n",
            "Epoch 568/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2482 - val_mse: 0.2482\n",
            "Epoch 569/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 570/1000\n",
            "2664/2664 [==============================] - 0s 140us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2523 - val_mse: 0.2523\n",
            "Epoch 571/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 572/1000\n",
            "2664/2664 [==============================] - 0s 136us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 573/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2167 - mse: 0.2167 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 574/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2113 - mse: 0.2113 - val_loss: 0.2558 - val_mse: 0.2558\n",
            "Epoch 575/1000\n",
            "2664/2664 [==============================] - 0s 138us/sample - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 576/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2165 - mse: 0.2165 - val_loss: 0.2601 - val_mse: 0.2601\n",
            "Epoch 577/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2454 - val_mse: 0.2454\n",
            "Epoch 578/1000\n",
            "2664/2664 [==============================] - 0s 136us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 579/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 580/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2528 - val_mse: 0.2528\n",
            "Epoch 581/1000\n",
            "2664/2664 [==============================] - 0s 142us/sample - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 582/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2553 - val_mse: 0.2553\n",
            "Epoch 583/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2155 - mse: 0.2155 - val_loss: 0.2547 - val_mse: 0.2547\n",
            "Epoch 584/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2113 - mse: 0.2113 - val_loss: 0.2511 - val_mse: 0.2511\n",
            "Epoch 585/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2534 - val_mse: 0.2534\n",
            "Epoch 586/1000\n",
            "2664/2664 [==============================] - 0s 139us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 587/1000\n",
            "2664/2664 [==============================] - 0s 138us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2566 - val_mse: 0.2566\n",
            "Epoch 588/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 589/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2465 - val_mse: 0.2465\n",
            "Epoch 590/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2479 - val_mse: 0.2479\n",
            "Epoch 591/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2100 - mse: 0.2100 - val_loss: 0.2487 - val_mse: 0.2487\n",
            "Epoch 592/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2085 - mse: 0.2085 - val_loss: 0.2605 - val_mse: 0.2605\n",
            "Epoch 593/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2157 - mse: 0.2157 - val_loss: 0.2513 - val_mse: 0.2513\n",
            "Epoch 594/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2130 - mse: 0.2130 - val_loss: 0.2540 - val_mse: 0.2540\n",
            "Epoch 595/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2553 - val_mse: 0.2553\n",
            "Epoch 596/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 597/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2105 - mse: 0.2105 - val_loss: 0.2547 - val_mse: 0.2547\n",
            "Epoch 598/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2564 - val_mse: 0.2564\n",
            "Epoch 599/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 600/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2473 - val_mse: 0.2473\n",
            "Epoch 601/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2477 - val_mse: 0.2477\n",
            "Epoch 602/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2166 - mse: 0.2166 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 603/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2087 - mse: 0.2087 - val_loss: 0.2472 - val_mse: 0.2472\n",
            "Epoch 604/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2472 - val_mse: 0.2472\n",
            "Epoch 605/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2111 - mse: 0.2111 - val_loss: 0.2524 - val_mse: 0.2524\n",
            "Epoch 606/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2099 - mse: 0.2099 - val_loss: 0.2488 - val_mse: 0.2488\n",
            "Epoch 607/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2154 - mse: 0.2154 - val_loss: 0.2528 - val_mse: 0.2528\n",
            "Epoch 608/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2554 - val_mse: 0.2554\n",
            "Epoch 609/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2489 - val_mse: 0.2489\n",
            "Epoch 610/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2489 - val_mse: 0.2489\n",
            "Epoch 611/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2119 - mse: 0.2119 - val_loss: 0.2478 - val_mse: 0.2478\n",
            "Epoch 612/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2565 - val_mse: 0.2565\n",
            "Epoch 613/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2175 - mse: 0.2175 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 614/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2544 - val_mse: 0.2544\n",
            "Epoch 615/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 616/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 617/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2545 - val_mse: 0.2545\n",
            "Epoch 618/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2532 - val_mse: 0.2532\n",
            "Epoch 619/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "Epoch 620/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2168 - mse: 0.2168 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 621/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "Epoch 622/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2175 - mse: 0.2175 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 623/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2556 - val_mse: 0.2556\n",
            "Epoch 624/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2514 - val_mse: 0.2514\n",
            "Epoch 625/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2557 - val_mse: 0.2557\n",
            "Epoch 626/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 627/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2080 - mse: 0.2080 - val_loss: 0.2524 - val_mse: 0.2524\n",
            "Epoch 628/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2098 - mse: 0.2098 - val_loss: 0.2536 - val_mse: 0.2536\n",
            "Epoch 629/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2482 - val_mse: 0.2482\n",
            "Epoch 630/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2539 - val_mse: 0.2539\n",
            "Epoch 631/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 632/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2509 - val_mse: 0.2509\n",
            "Epoch 633/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 634/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 635/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2581 - val_mse: 0.2581\n",
            "Epoch 636/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2154 - mse: 0.2154 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 637/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2463 - val_mse: 0.2463\n",
            "Epoch 638/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2480 - val_mse: 0.2480\n",
            "Epoch 639/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2472 - val_mse: 0.2472\n",
            "Epoch 640/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2567 - val_mse: 0.2567\n",
            "Epoch 641/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2508 - val_mse: 0.2508\n",
            "Epoch 642/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2096 - mse: 0.2096 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 643/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2113 - mse: 0.2113 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 644/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 645/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2534 - val_mse: 0.2534\n",
            "Epoch 646/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2119 - mse: 0.2119 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "Epoch 647/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2100 - mse: 0.2100 - val_loss: 0.2524 - val_mse: 0.2524\n",
            "Epoch 648/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2519 - val_mse: 0.2519\n",
            "Epoch 649/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 650/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2511 - val_mse: 0.2511\n",
            "Epoch 651/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 652/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2522 - val_mse: 0.2522\n",
            "Epoch 653/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "Epoch 654/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2093 - mse: 0.2093 - val_loss: 0.2479 - val_mse: 0.2479\n",
            "Epoch 655/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2511 - val_mse: 0.2511\n",
            "Epoch 656/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2559 - val_mse: 0.2559\n",
            "Epoch 657/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2553 - val_mse: 0.2553\n",
            "Epoch 658/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2097 - mse: 0.2097 - val_loss: 0.2558 - val_mse: 0.2558\n",
            "Epoch 659/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 660/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 661/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2572 - val_mse: 0.2572\n",
            "Epoch 662/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2523 - val_mse: 0.2523\n",
            "Epoch 663/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2586 - val_mse: 0.2586\n",
            "Epoch 664/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2557 - val_mse: 0.2557\n",
            "Epoch 665/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 666/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.2555 - val_mse: 0.2555\n",
            "Epoch 667/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 668/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2107 - mse: 0.2107 - val_loss: 0.2587 - val_mse: 0.2587\n",
            "Epoch 669/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2476 - val_mse: 0.2476\n",
            "Epoch 670/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2096 - mse: 0.2096 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 671/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2538 - val_mse: 0.2538\n",
            "Epoch 672/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2519 - val_mse: 0.2519\n",
            "Epoch 673/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 674/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2556 - val_mse: 0.2556\n",
            "Epoch 675/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2551 - val_mse: 0.2551\n",
            "Epoch 676/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 677/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2480 - val_mse: 0.2480\n",
            "Epoch 678/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2540 - val_mse: 0.2540\n",
            "Epoch 679/1000\n",
            "2664/2664 [==============================] - 0s 139us/sample - loss: 0.2103 - mse: 0.2103 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 680/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2158 - mse: 0.2158 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 681/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2479 - val_mse: 0.2479\n",
            "Epoch 682/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2526 - val_mse: 0.2526\n",
            "Epoch 683/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2107 - mse: 0.2107 - val_loss: 0.2483 - val_mse: 0.2483\n",
            "Epoch 684/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 685/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2107 - mse: 0.2107 - val_loss: 0.2492 - val_mse: 0.2492\n",
            "Epoch 686/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "Epoch 687/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2152 - mse: 0.2152 - val_loss: 0.2541 - val_mse: 0.2541\n",
            "Epoch 688/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2115 - mse: 0.2115 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 689/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 690/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2529 - val_mse: 0.2529\n",
            "Epoch 691/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2523 - val_mse: 0.2523\n",
            "Epoch 692/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 693/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 694/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2172 - mse: 0.2172 - val_loss: 0.2544 - val_mse: 0.2544\n",
            "Epoch 695/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2515 - val_mse: 0.2515\n",
            "Epoch 696/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2111 - mse: 0.2111 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 697/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2522 - val_mse: 0.2522\n",
            "Epoch 698/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2153 - mse: 0.2153 - val_loss: 0.2531 - val_mse: 0.2531\n",
            "Epoch 699/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 700/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 701/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2483 - val_mse: 0.2483\n",
            "Epoch 702/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2119 - mse: 0.2119 - val_loss: 0.2586 - val_mse: 0.2586\n",
            "Epoch 703/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2529 - val_mse: 0.2529\n",
            "Epoch 704/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2095 - mse: 0.2095 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 705/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 706/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2455 - val_mse: 0.2455\n",
            "Epoch 707/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2485 - val_mse: 0.2485\n",
            "Epoch 708/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2095 - mse: 0.2095 - val_loss: 0.2519 - val_mse: 0.2519\n",
            "Epoch 709/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 710/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2531 - val_mse: 0.2531\n",
            "Epoch 711/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2097 - mse: 0.2097 - val_loss: 0.2539 - val_mse: 0.2539\n",
            "Epoch 712/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.2494 - val_mse: 0.2494\n",
            "Epoch 713/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 714/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2532 - val_mse: 0.2532\n",
            "Epoch 715/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 716/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2174 - mse: 0.2174 - val_loss: 0.2491 - val_mse: 0.2491\n",
            "Epoch 717/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2155 - mse: 0.2155 - val_loss: 0.2446 - val_mse: 0.2446\n",
            "Epoch 718/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2456 - val_mse: 0.2456\n",
            "Epoch 719/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 720/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2514 - val_mse: 0.2514\n",
            "Epoch 721/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2107 - mse: 0.2107 - val_loss: 0.2492 - val_mse: 0.2492\n",
            "Epoch 722/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2544 - val_mse: 0.2544\n",
            "Epoch 723/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2547 - val_mse: 0.2547\n",
            "Epoch 724/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2171 - mse: 0.2171 - val_loss: 0.2568 - val_mse: 0.2568\n",
            "Epoch 725/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 726/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2086 - mse: 0.2086 - val_loss: 0.2478 - val_mse: 0.2478\n",
            "Epoch 727/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 728/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2487 - val_mse: 0.2487\n",
            "Epoch 729/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2534 - val_mse: 0.2534\n",
            "Epoch 730/1000\n",
            "2664/2664 [==============================] - 0s 118us/sample - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 731/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "Epoch 732/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2093 - mse: 0.2093 - val_loss: 0.2521 - val_mse: 0.2521\n",
            "Epoch 733/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2097 - mse: 0.2097 - val_loss: 0.2612 - val_mse: 0.2612\n",
            "Epoch 734/1000\n",
            "2664/2664 [==============================] - 0s 118us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2508 - val_mse: 0.2508\n",
            "Epoch 735/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2182 - mse: 0.2182 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 736/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2118 - mse: 0.2118 - val_loss: 0.2451 - val_mse: 0.2451\n",
            "Epoch 737/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2492 - val_mse: 0.2492\n",
            "Epoch 738/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2477 - val_mse: 0.2477\n",
            "Epoch 739/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 740/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2105 - mse: 0.2105 - val_loss: 0.2554 - val_mse: 0.2554\n",
            "Epoch 741/1000\n",
            "2664/2664 [==============================] - 0s 139us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 742/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 743/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2524 - val_mse: 0.2524\n",
            "Epoch 744/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2087 - mse: 0.2087 - val_loss: 0.2541 - val_mse: 0.2541\n",
            "Epoch 745/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2091 - mse: 0.2091 - val_loss: 0.2561 - val_mse: 0.2561\n",
            "Epoch 746/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2478 - val_mse: 0.2478\n",
            "Epoch 747/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2130 - mse: 0.2130 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 748/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2205 - mse: 0.2204 - val_loss: 0.2486 - val_mse: 0.2486\n",
            "Epoch 749/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2173 - mse: 0.2173 - val_loss: 0.2571 - val_mse: 0.2571\n",
            "Epoch 750/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2113 - mse: 0.2113 - val_loss: 0.2512 - val_mse: 0.2512\n",
            "Epoch 751/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2115 - mse: 0.2115 - val_loss: 0.2512 - val_mse: 0.2512\n",
            "Epoch 752/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 753/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2103 - mse: 0.2103 - val_loss: 0.2515 - val_mse: 0.2515\n",
            "Epoch 754/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2577 - val_mse: 0.2577\n",
            "Epoch 755/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2155 - mse: 0.2155 - val_loss: 0.2475 - val_mse: 0.2475\n",
            "Epoch 756/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2154 - mse: 0.2154 - val_loss: 0.2457 - val_mse: 0.2457\n",
            "Epoch 757/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2157 - mse: 0.2157 - val_loss: 0.2483 - val_mse: 0.2483\n",
            "Epoch 758/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "Epoch 759/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2518 - val_mse: 0.2518\n",
            "Epoch 760/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2088 - mse: 0.2088 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 761/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2530 - val_mse: 0.2530\n",
            "Epoch 762/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2147 - mse: 0.2147 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 763/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2540 - val_mse: 0.2540\n",
            "Epoch 764/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2551 - val_mse: 0.2551\n",
            "Epoch 765/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2583 - val_mse: 0.2583\n",
            "Epoch 766/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2570 - val_mse: 0.2570\n",
            "Epoch 767/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2534 - val_mse: 0.2534\n",
            "Epoch 768/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 769/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2119 - mse: 0.2119 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 770/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2533 - val_mse: 0.2533\n",
            "Epoch 771/1000\n",
            "2664/2664 [==============================] - 0s 138us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2546 - val_mse: 0.2546\n",
            "Epoch 772/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2090 - mse: 0.2090 - val_loss: 0.2622 - val_mse: 0.2622\n",
            "Epoch 773/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 774/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2111 - mse: 0.2111 - val_loss: 0.2558 - val_mse: 0.2558\n",
            "Epoch 775/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2105 - mse: 0.2105 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 776/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 777/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2118 - mse: 0.2118 - val_loss: 0.2545 - val_mse: 0.2545\n",
            "Epoch 778/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2530 - val_mse: 0.2530\n",
            "Epoch 779/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2554 - val_mse: 0.2554\n",
            "Epoch 780/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2082 - mse: 0.2082 - val_loss: 0.2487 - val_mse: 0.2487\n",
            "Epoch 781/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2519 - val_mse: 0.2519\n",
            "Epoch 782/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2095 - mse: 0.2095 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 783/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2118 - mse: 0.2118 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 784/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2094 - mse: 0.2094 - val_loss: 0.2533 - val_mse: 0.2533\n",
            "Epoch 785/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2559 - val_mse: 0.2559\n",
            "Epoch 786/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.2584 - val_mse: 0.2584\n",
            "Epoch 787/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2097 - mse: 0.2097 - val_loss: 0.2519 - val_mse: 0.2519\n",
            "Epoch 788/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2589 - val_mse: 0.2589\n",
            "Epoch 789/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2119 - mse: 0.2119 - val_loss: 0.2530 - val_mse: 0.2530\n",
            "Epoch 790/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2522 - val_mse: 0.2522\n",
            "Epoch 791/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2130 - mse: 0.2130 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 792/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2513 - val_mse: 0.2513\n",
            "Epoch 793/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2165 - mse: 0.2165 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 794/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 795/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2147 - mse: 0.2147 - val_loss: 0.2450 - val_mse: 0.2450\n",
            "Epoch 796/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2160 - mse: 0.2160 - val_loss: 0.2474 - val_mse: 0.2474\n",
            "Epoch 797/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 798/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 799/1000\n",
            "2664/2664 [==============================] - 0s 119us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2494 - val_mse: 0.2494\n",
            "Epoch 800/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2118 - mse: 0.2118 - val_loss: 0.2567 - val_mse: 0.2567\n",
            "Epoch 801/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 802/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2473 - val_mse: 0.2473\n",
            "Epoch 803/1000\n",
            "2664/2664 [==============================] - 0s 145us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2603 - val_mse: 0.2603\n",
            "Epoch 804/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2480 - val_mse: 0.2480\n",
            "Epoch 805/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2087 - mse: 0.2087 - val_loss: 0.2541 - val_mse: 0.2541\n",
            "Epoch 806/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2513 - val_mse: 0.2513\n",
            "Epoch 807/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2107 - mse: 0.2107 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 808/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 809/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2472 - val_mse: 0.2472\n",
            "Epoch 810/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2488 - val_mse: 0.2488\n",
            "Epoch 811/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2102 - mse: 0.2102 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 812/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 813/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2514 - val_mse: 0.2514\n",
            "Epoch 814/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2099 - mse: 0.2099 - val_loss: 0.2535 - val_mse: 0.2535\n",
            "Epoch 815/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2103 - mse: 0.2103 - val_loss: 0.2508 - val_mse: 0.2508\n",
            "Epoch 816/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2097 - mse: 0.2097 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 817/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2523 - val_mse: 0.2523\n",
            "Epoch 818/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2131 - mse: 0.2131 - val_loss: 0.2558 - val_mse: 0.2558\n",
            "Epoch 819/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2143 - mse: 0.2143 - val_loss: 0.2587 - val_mse: 0.2587\n",
            "Epoch 820/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 821/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2136 - mse: 0.2136 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "Epoch 822/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 823/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2563 - val_mse: 0.2563\n",
            "Epoch 824/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2147 - mse: 0.2147 - val_loss: 0.2491 - val_mse: 0.2491\n",
            "Epoch 825/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2513 - val_mse: 0.2513\n",
            "Epoch 826/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2161 - mse: 0.2161 - val_loss: 0.2491 - val_mse: 0.2491\n",
            "Epoch 827/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2471 - val_mse: 0.2471\n",
            "Epoch 828/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2136 - mse: 0.2136 - val_loss: 0.2460 - val_mse: 0.2460\n",
            "Epoch 829/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 830/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 831/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.2558 - val_mse: 0.2558\n",
            "Epoch 832/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2492 - val_mse: 0.2492\n",
            "Epoch 833/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2137 - mse: 0.2137 - val_loss: 0.2546 - val_mse: 0.2546\n",
            "Epoch 834/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2136 - mse: 0.2136 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 835/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2112 - mse: 0.2112 - val_loss: 0.2523 - val_mse: 0.2523\n",
            "Epoch 836/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2099 - mse: 0.2099 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 837/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2165 - mse: 0.2165 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 838/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2088 - mse: 0.2088 - val_loss: 0.2528 - val_mse: 0.2528\n",
            "Epoch 839/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2082 - mse: 0.2082 - val_loss: 0.2519 - val_mse: 0.2519\n",
            "Epoch 840/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2091 - mse: 0.2091 - val_loss: 0.2538 - val_mse: 0.2538\n",
            "Epoch 841/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2539 - val_mse: 0.2539\n",
            "Epoch 842/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2536 - val_mse: 0.2536\n",
            "Epoch 843/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2096 - mse: 0.2096 - val_loss: 0.2574 - val_mse: 0.2574\n",
            "Epoch 844/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2538 - val_mse: 0.2538\n",
            "Epoch 845/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2103 - mse: 0.2103 - val_loss: 0.2519 - val_mse: 0.2519\n",
            "Epoch 846/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2525 - val_mse: 0.2525\n",
            "Epoch 847/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2541 - val_mse: 0.2541\n",
            "Epoch 848/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2089 - mse: 0.2089 - val_loss: 0.2509 - val_mse: 0.2509\n",
            "Epoch 849/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 850/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2481 - val_mse: 0.2481\n",
            "Epoch 851/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "Epoch 852/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 853/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2525 - val_mse: 0.2525\n",
            "Epoch 854/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2099 - mse: 0.2099 - val_loss: 0.2542 - val_mse: 0.2542\n",
            "Epoch 855/1000\n",
            "2664/2664 [==============================] - 0s 141us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2554 - val_mse: 0.2554\n",
            "Epoch 856/1000\n",
            "2664/2664 [==============================] - 0s 142us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 857/1000\n",
            "2664/2664 [==============================] - 0s 147us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2529 - val_mse: 0.2529\n",
            "Epoch 858/1000\n",
            "2664/2664 [==============================] - 0s 147us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2476 - val_mse: 0.2476\n",
            "Epoch 859/1000\n",
            "2664/2664 [==============================] - 0s 140us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2525 - val_mse: 0.2525\n",
            "Epoch 860/1000\n",
            "2664/2664 [==============================] - 0s 149us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2522 - val_mse: 0.2522\n",
            "Epoch 861/1000\n",
            "2664/2664 [==============================] - 0s 139us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2545 - val_mse: 0.2545\n",
            "Epoch 862/1000\n",
            "2664/2664 [==============================] - 0s 140us/sample - loss: 0.2094 - mse: 0.2094 - val_loss: 0.2483 - val_mse: 0.2483\n",
            "Epoch 863/1000\n",
            "2664/2664 [==============================] - 0s 158us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2556 - val_mse: 0.2556\n",
            "Epoch 864/1000\n",
            "2664/2664 [==============================] - 0s 147us/sample - loss: 0.2092 - mse: 0.2092 - val_loss: 0.2501 - val_mse: 0.2501\n",
            "Epoch 865/1000\n",
            "2664/2664 [==============================] - 0s 142us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 866/1000\n",
            "2664/2664 [==============================] - 0s 151us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2513 - val_mse: 0.2513\n",
            "Epoch 867/1000\n",
            "2664/2664 [==============================] - 0s 140us/sample - loss: 0.2130 - mse: 0.2130 - val_loss: 0.2492 - val_mse: 0.2492\n",
            "Epoch 868/1000\n",
            "2664/2664 [==============================] - 0s 138us/sample - loss: 0.2154 - mse: 0.2154 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 869/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2541 - val_mse: 0.2541\n",
            "Epoch 870/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2470 - val_mse: 0.2470\n",
            "Epoch 871/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2520 - val_mse: 0.2520\n",
            "Epoch 872/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2526 - val_mse: 0.2526\n",
            "Epoch 873/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2547 - val_mse: 0.2547\n",
            "Epoch 874/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2100 - mse: 0.2100 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 875/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 876/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 877/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2132 - mse: 0.2132 - val_loss: 0.2466 - val_mse: 0.2466\n",
            "Epoch 878/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2126 - mse: 0.2126 - val_loss: 0.2493 - val_mse: 0.2493\n",
            "Epoch 879/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 880/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2511 - val_mse: 0.2511\n",
            "Epoch 881/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2100 - mse: 0.2100 - val_loss: 0.2524 - val_mse: 0.2524\n",
            "Epoch 882/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2125 - mse: 0.2125 - val_loss: 0.2582 - val_mse: 0.2582\n",
            "Epoch 883/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2134 - mse: 0.2134 - val_loss: 0.2571 - val_mse: 0.2571\n",
            "Epoch 884/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2077 - mse: 0.2077 - val_loss: 0.2479 - val_mse: 0.2479\n",
            "Epoch 885/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2138 - mse: 0.2138 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 886/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 887/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2107 - mse: 0.2107 - val_loss: 0.2535 - val_mse: 0.2535\n",
            "Epoch 888/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2089 - mse: 0.2089 - val_loss: 0.2499 - val_mse: 0.2499\n",
            "Epoch 889/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2130 - mse: 0.2130 - val_loss: 0.2476 - val_mse: 0.2476\n",
            "Epoch 890/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2136 - mse: 0.2136 - val_loss: 0.2528 - val_mse: 0.2528\n",
            "Epoch 891/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2115 - mse: 0.2115 - val_loss: 0.2601 - val_mse: 0.2601\n",
            "Epoch 892/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2141 - mse: 0.2141 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 893/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2497 - val_mse: 0.2497\n",
            "Epoch 894/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2458 - val_mse: 0.2458\n",
            "Epoch 895/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2115 - mse: 0.2115 - val_loss: 0.2481 - val_mse: 0.2481\n",
            "Epoch 896/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 897/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2089 - mse: 0.2089 - val_loss: 0.2560 - val_mse: 0.2560\n",
            "Epoch 898/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2496 - val_mse: 0.2496\n",
            "Epoch 899/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2128 - mse: 0.2128 - val_loss: 0.2568 - val_mse: 0.2568\n",
            "Epoch 900/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2487 - val_mse: 0.2487\n",
            "Epoch 901/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2511 - val_mse: 0.2511\n",
            "Epoch 902/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2518 - val_mse: 0.2518\n",
            "Epoch 903/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2148 - mse: 0.2148 - val_loss: 0.2586 - val_mse: 0.2586\n",
            "Epoch 904/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2513 - val_mse: 0.2513\n",
            "Epoch 905/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2135 - mse: 0.2135 - val_loss: 0.2511 - val_mse: 0.2511\n",
            "Epoch 906/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2504 - val_mse: 0.2504\n",
            "Epoch 907/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2080 - mse: 0.2080 - val_loss: 0.2520 - val_mse: 0.2520\n",
            "Epoch 908/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2117 - mse: 0.2117 - val_loss: 0.2521 - val_mse: 0.2521\n",
            "Epoch 909/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2121 - mse: 0.2122 - val_loss: 0.2518 - val_mse: 0.2518\n",
            "Epoch 910/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2103 - mse: 0.2103 - val_loss: 0.2531 - val_mse: 0.2531\n",
            "Epoch 911/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2476 - val_mse: 0.2476\n",
            "Epoch 912/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2145 - mse: 0.2145 - val_loss: 0.2622 - val_mse: 0.2622\n",
            "Epoch 913/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2144 - mse: 0.2144 - val_loss: 0.2531 - val_mse: 0.2531\n",
            "Epoch 914/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2537 - val_mse: 0.2537\n",
            "Epoch 915/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 916/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2120 - mse: 0.2120 - val_loss: 0.2552 - val_mse: 0.2552\n",
            "Epoch 917/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2107 - mse: 0.2107 - val_loss: 0.2539 - val_mse: 0.2539\n",
            "Epoch 918/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2105 - mse: 0.2105 - val_loss: 0.2645 - val_mse: 0.2645\n",
            "Epoch 919/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2158 - mse: 0.2158 - val_loss: 0.2557 - val_mse: 0.2557\n",
            "Epoch 920/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2487 - val_mse: 0.2487\n",
            "Epoch 921/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2146 - mse: 0.2146 - val_loss: 0.2484 - val_mse: 0.2484\n",
            "Epoch 922/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2099 - mse: 0.2099 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "Epoch 923/1000\n",
            "2664/2664 [==============================] - 0s 147us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2533 - val_mse: 0.2533\n",
            "Epoch 924/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2094 - mse: 0.2094 - val_loss: 0.2529 - val_mse: 0.2529\n",
            "Epoch 925/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2172 - mse: 0.2172 - val_loss: 0.2490 - val_mse: 0.2490\n",
            "Epoch 926/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2094 - mse: 0.2094 - val_loss: 0.2566 - val_mse: 0.2566\n",
            "Epoch 927/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2160 - mse: 0.2160 - val_loss: 0.2533 - val_mse: 0.2533\n",
            "Epoch 928/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2163 - mse: 0.2163 - val_loss: 0.2508 - val_mse: 0.2508\n",
            "Epoch 929/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2113 - mse: 0.2113 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 930/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2098 - mse: 0.2098 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 931/1000\n",
            "2664/2664 [==============================] - 0s 137us/sample - loss: 0.2113 - mse: 0.2113 - val_loss: 0.2521 - val_mse: 0.2521\n",
            "Epoch 932/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2549 - val_mse: 0.2549\n",
            "Epoch 933/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2160 - mse: 0.2160 - val_loss: 0.2531 - val_mse: 0.2531\n",
            "Epoch 934/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2111 - mse: 0.2111 - val_loss: 0.2526 - val_mse: 0.2526\n",
            "Epoch 935/1000\n",
            "2664/2664 [==============================] - 0s 139us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2512 - val_mse: 0.2512\n",
            "Epoch 936/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2491 - val_mse: 0.2491\n",
            "Epoch 937/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2508 - val_mse: 0.2508\n",
            "Epoch 938/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2113 - mse: 0.2113 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "Epoch 939/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2512 - val_mse: 0.2512\n",
            "Epoch 940/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 941/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2115 - mse: 0.2115 - val_loss: 0.2543 - val_mse: 0.2543\n",
            "Epoch 942/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2086 - mse: 0.2086 - val_loss: 0.2480 - val_mse: 0.2480\n",
            "Epoch 943/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2103 - mse: 0.2103 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 944/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2133 - mse: 0.2133 - val_loss: 0.2521 - val_mse: 0.2521\n",
            "Epoch 945/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2127 - mse: 0.2127 - val_loss: 0.2508 - val_mse: 0.2508\n",
            "Epoch 946/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2108 - mse: 0.2108 - val_loss: 0.2542 - val_mse: 0.2542\n",
            "Epoch 947/1000\n",
            "2664/2664 [==============================] - 0s 132us/sample - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2469 - val_mse: 0.2469\n",
            "Epoch 948/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2535 - val_mse: 0.2535\n",
            "Epoch 949/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2118 - mse: 0.2118 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 950/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2085 - mse: 0.2085 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 951/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2076 - mse: 0.2076 - val_loss: 0.2500 - val_mse: 0.2500\n",
            "Epoch 952/1000\n",
            "2664/2664 [==============================] - 0s 141us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 953/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2098 - mse: 0.2098 - val_loss: 0.2513 - val_mse: 0.2513\n",
            "Epoch 954/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2118 - mse: 0.2118 - val_loss: 0.2508 - val_mse: 0.2508\n",
            "Epoch 955/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "Epoch 956/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2498 - val_mse: 0.2498\n",
            "Epoch 957/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2087 - mse: 0.2087 - val_loss: 0.2531 - val_mse: 0.2531\n",
            "Epoch 958/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2105 - mse: 0.2105 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 959/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2096 - mse: 0.2096 - val_loss: 0.2572 - val_mse: 0.2572\n",
            "Epoch 960/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2094 - mse: 0.2094 - val_loss: 0.2539 - val_mse: 0.2539\n",
            "Epoch 961/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2551 - val_mse: 0.2551\n",
            "Epoch 962/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2085 - mse: 0.2085 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 963/1000\n",
            "2664/2664 [==============================] - 0s 130us/sample - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2578 - val_mse: 0.2578\n",
            "Epoch 964/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2124 - mse: 0.2124 - val_loss: 0.2605 - val_mse: 0.2605\n",
            "Epoch 965/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2106 - mse: 0.2106 - val_loss: 0.2520 - val_mse: 0.2520\n",
            "Epoch 966/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2116 - mse: 0.2116 - val_loss: 0.2526 - val_mse: 0.2526\n",
            "Epoch 967/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2088 - mse: 0.2088 - val_loss: 0.2512 - val_mse: 0.2512\n",
            "Epoch 968/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2150 - mse: 0.2150 - val_loss: 0.2507 - val_mse: 0.2507\n",
            "Epoch 969/1000\n",
            "2664/2664 [==============================] - 0s 133us/sample - loss: 0.2147 - mse: 0.2147 - val_loss: 0.2521 - val_mse: 0.2521\n",
            "Epoch 970/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2109 - mse: 0.2109 - val_loss: 0.2514 - val_mse: 0.2514\n",
            "Epoch 971/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2492 - val_mse: 0.2492\n",
            "Epoch 972/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2121 - mse: 0.2121 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "Epoch 973/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2489 - val_mse: 0.2489\n",
            "Epoch 974/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2104 - mse: 0.2104 - val_loss: 0.2538 - val_mse: 0.2538\n",
            "Epoch 975/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2095 - mse: 0.2095 - val_loss: 0.2520 - val_mse: 0.2520\n",
            "Epoch 976/1000\n",
            "2664/2664 [==============================] - 0s 135us/sample - loss: 0.2093 - mse: 0.2093 - val_loss: 0.2475 - val_mse: 0.2475\n",
            "Epoch 977/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2139 - mse: 0.2139 - val_loss: 0.2520 - val_mse: 0.2520\n",
            "Epoch 978/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2149 - mse: 0.2149 - val_loss: 0.2523 - val_mse: 0.2523\n",
            "Epoch 979/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2096 - mse: 0.2096 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 980/1000\n",
            "2664/2664 [==============================] - 0s 124us/sample - loss: 0.2084 - mse: 0.2084 - val_loss: 0.2547 - val_mse: 0.2547\n",
            "Epoch 981/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2103 - mse: 0.2103 - val_loss: 0.2502 - val_mse: 0.2502\n",
            "Epoch 982/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2097 - mse: 0.2097 - val_loss: 0.2517 - val_mse: 0.2517\n",
            "Epoch 983/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2103 - mse: 0.2103 - val_loss: 0.2515 - val_mse: 0.2515\n",
            "Epoch 984/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2122 - mse: 0.2122 - val_loss: 0.2512 - val_mse: 0.2512\n",
            "Epoch 985/1000\n",
            "2664/2664 [==============================] - 0s 134us/sample - loss: 0.2082 - mse: 0.2082 - val_loss: 0.2535 - val_mse: 0.2535\n",
            "Epoch 986/1000\n",
            "2664/2664 [==============================] - 0s 123us/sample - loss: 0.2097 - mse: 0.2097 - val_loss: 0.2505 - val_mse: 0.2505\n",
            "Epoch 987/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2115 - mse: 0.2115 - val_loss: 0.2506 - val_mse: 0.2506\n",
            "Epoch 988/1000\n",
            "2664/2664 [==============================] - 0s 128us/sample - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2523 - val_mse: 0.2523\n",
            "Epoch 989/1000\n",
            "2664/2664 [==============================] - 0s 122us/sample - loss: 0.2097 - mse: 0.2097 - val_loss: 0.2509 - val_mse: 0.2509\n",
            "Epoch 990/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2101 - mse: 0.2101 - val_loss: 0.2578 - val_mse: 0.2578\n",
            "Epoch 991/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2614 - val_mse: 0.2614\n",
            "Epoch 992/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2114 - mse: 0.2114 - val_loss: 0.2521 - val_mse: 0.2521\n",
            "Epoch 993/1000\n",
            "2664/2664 [==============================] - 0s 131us/sample - loss: 0.2147 - mse: 0.2147 - val_loss: 0.2614 - val_mse: 0.2614\n",
            "Epoch 994/1000\n",
            "2664/2664 [==============================] - 0s 129us/sample - loss: 0.2113 - mse: 0.2113 - val_loss: 0.2513 - val_mse: 0.2513\n",
            "Epoch 995/1000\n",
            "2664/2664 [==============================] - 0s 121us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2510 - val_mse: 0.2510\n",
            "Epoch 996/1000\n",
            "2664/2664 [==============================] - 0s 125us/sample - loss: 0.2129 - mse: 0.2129 - val_loss: 0.2516 - val_mse: 0.2516\n",
            "Epoch 997/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2113 - mse: 0.2113 - val_loss: 0.2511 - val_mse: 0.2511\n",
            "Epoch 998/1000\n",
            "2664/2664 [==============================] - 0s 127us/sample - loss: 0.2111 - mse: 0.2111 - val_loss: 0.2555 - val_mse: 0.2555\n",
            "Epoch 999/1000\n",
            "2664/2664 [==============================] - 0s 126us/sample - loss: 0.2110 - mse: 0.2110 - val_loss: 0.2522 - val_mse: 0.2522\n",
            "Epoch 1000/1000\n",
            "2664/2664 [==============================] - 0s 120us/sample - loss: 0.2083 - mse: 0.2083 - val_loss: 0.2516 - val_mse: 0.2516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa8111ff2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m76ko-fQ106u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "232cdaa5-dad7-4812-f2b8-a059de67b4ae"
      },
      "source": [
        "y_scores = model.predict(X_validation)\n",
        "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error\n",
        "\n",
        "score = mean_squared_error(y_validation, y_scores)\n",
        "print(\"mse score on 20 percent data:\",score)\n",
        "score = mean_absolute_error(y_validation, y_scores)\n",
        "print(\"mae score on 20percent data:\",score)\n",
        "# to check the fit on 5 percent validation we plot yscores vs yvalidation and see how much it follows y=x line\n",
        "\n",
        "a=[]\n",
        "for i in range(0,2000):\n",
        "  a.append(i/1000)\n",
        "plt.scatter(np.array(a),np.array(a), s=0.05, c='r', alpha=0.1)\n",
        "plt.scatter(y_scores,y_validation, s=0.05, c='b', alpha=0.8)\n",
        "plt.title(\"grunet on 20 percent val\")\n",
        "plt.xlabel('prediction')\n",
        "plt.ylabel('actual values')\n",
        "plt.savefig('/content/drive/My Drive/hack/data analysis/'+\"gru_regression_test_20percent\"+'.jpg',)\n",
        "plt.show()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mse score on 20 percent data: 0.25156831762967097\n",
            "mae score on 20percent data: 0.20812003110032248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SYeMGBP7MM5",
        "colab_type": "text"
      },
      "source": [
        "NOW to train on 95 percent data since the model looks good when trained on 80 percent data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z5WBIn2h7Ezd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb4ff2aa-1ca8-4695-b110-19cddfde3e0f"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense,Lambda\n",
        "import numpy as np\n",
        "\n",
        "data_dim = 1\n",
        "timesteps = 5\n",
        "nb_classes = 1\n",
        "# expected input data shape: (batch_size, timesteps, data_dim)\n",
        "model = Sequential()\n",
        "model.add(GRU(64, return_sequences=True,\n",
        "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
        "model.add(Dropout(0.5))               \n",
        "model.add(GRU(64, return_sequences=False))  # returns a sequence of vectors of dimension 32\n",
        "#model.add(GRU(32))  # return a single vector of dimension 32\n",
        "model.add(Dropout(0.5))              \n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.add(Lambda(lambda x: x*2))# to get output in (0,2)\n",
        "model.compile(loss='mse',\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              metrics=['mse'])\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(train, y, train_size=0.95, random_state=1234)\n",
        "#remove rows with misssing values in target y\n",
        "new_x_train =[]\n",
        "new_y_train = []\n",
        "for i in range(y_train.shape[0]):\n",
        "  if y_train[i]!= -1:\n",
        "    new_y_train.append(y_train[i])\n",
        "    new_x_train.append(X_train[i])\n",
        "new_y_train = np.array(new_y_train)\n",
        "\n",
        "new_x_train = np.array(new_x_train)\n",
        "\n",
        "new_x_validation =[]\n",
        "new_y_validation = []\n",
        "for i in range(y_validation.shape[0]):\n",
        "  if y_validation[i]!= -1:\n",
        "    new_y_validation.append(y_validation[i])\n",
        "    new_x_validation.append(X_validation[i])\n",
        "new_y_validation = np.array(new_y_validation)\n",
        "\n",
        "new_x_validation = np.array(new_x_validation)\n",
        "print(new_x_train.shape,new_y_train.shape)\n",
        "print(new_x_validation.shape,new_y_validation.shape)\n",
        "model.fit(new_x_train, new_y_train,\n",
        "          batch_size=64,epochs=200,\n",
        "          validation_data=(new_x_validation, new_y_validation))\n",
        "model.save('/content/drive/My Drive/hack/models/gru.h5')\n",
        "y_scores = model.predict(X_validation)\n",
        "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error\n",
        "\n",
        "score = mean_squared_error(y_validation, y_scores)\n",
        "print(\"mse score on 5 percent data:\",score)\n",
        "score = mean_absolute_error(y_validation, y_scores)\n",
        "print(\"mae score on 5 percent data:\",score)\n",
        "# to check the fit on 5 percent validation we plot yscores vs yvalidation and see how much it follows y=x line\n",
        "\n",
        "a=[]\n",
        "for i in range(0,2000):\n",
        "  a.append(i/1000)\n",
        "plt.scatter(np.array(a),np.array(a), s=0.05, c='r', alpha=0.1)\n",
        "plt.scatter(y_scores,y_validation, s=0.05, c='b', alpha=0.8)\n",
        "plt.title(\"grunet on 5 percent val\")\n",
        "plt.xlabel('prediction')\n",
        "plt.ylabel('actual values')\n",
        "plt.savefig('/content/drive/My Drive/hack/data analysis/'+\"gru_regression_test_final\"+'.jpg',)\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2941, 5, 1) (2941, 1)\n",
            "(151, 5, 1) (151, 1)\n",
            "Train on 2941 samples, validate on 151 samples\n",
            "Epoch 1/200\n",
            "2941/2941 [==============================] - 2s 660us/sample - loss: 0.1260 - mse: 0.1260 - val_loss: 0.0611 - val_mse: 0.0611\n",
            "Epoch 2/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 3/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 4/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 5/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0071 - val_mse: 0.0071\n",
            "Epoch 6/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 7/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 8/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 9/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 10/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 11/200\n",
            "2941/2941 [==============================] - 0s 141us/sample - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 12/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 13/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 14/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 15/200\n",
            "2941/2941 [==============================] - 0s 146us/sample - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 16/200\n",
            "2941/2941 [==============================] - 0s 142us/sample - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 17/200\n",
            "2941/2941 [==============================] - 0s 147us/sample - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0015 - val_mse: 0.0015\n",
            "Epoch 18/200\n",
            "2941/2941 [==============================] - 0s 149us/sample - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 19/200\n",
            "2941/2941 [==============================] - 0s 146us/sample - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 20/200\n",
            "2941/2941 [==============================] - 0s 150us/sample - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 21/200\n",
            "2941/2941 [==============================] - 0s 145us/sample - loss: 0.0035 - mse: 0.0035 - val_loss: 8.4261e-04 - val_mse: 8.4261e-04\n",
            "Epoch 22/200\n",
            "2941/2941 [==============================] - 0s 147us/sample - loss: 0.0035 - mse: 0.0035 - val_loss: 8.5639e-04 - val_mse: 8.5639e-04\n",
            "Epoch 23/200\n",
            "2941/2941 [==============================] - 0s 153us/sample - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 24/200\n",
            "2941/2941 [==============================] - 0s 145us/sample - loss: 0.0037 - mse: 0.0037 - val_loss: 9.8066e-04 - val_mse: 9.8066e-04\n",
            "Epoch 25/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0037 - mse: 0.0037 - val_loss: 6.8041e-04 - val_mse: 6.8041e-04\n",
            "Epoch 26/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0033 - mse: 0.0033 - val_loss: 6.3985e-04 - val_mse: 6.3985e-04\n",
            "Epoch 27/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0033 - mse: 0.0033 - val_loss: 7.6406e-04 - val_mse: 7.6406e-04\n",
            "Epoch 28/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 29/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0035 - mse: 0.0035 - val_loss: 5.9583e-04 - val_mse: 5.9583e-04\n",
            "Epoch 30/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0032 - mse: 0.0032 - val_loss: 8.1905e-04 - val_mse: 8.1905e-04\n",
            "Epoch 31/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0031 - mse: 0.0031 - val_loss: 5.2674e-04 - val_mse: 5.2674e-04\n",
            "Epoch 32/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 33/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0031 - mse: 0.0031 - val_loss: 5.9402e-04 - val_mse: 5.9402e-04\n",
            "Epoch 34/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0030 - mse: 0.0030 - val_loss: 8.3685e-04 - val_mse: 8.3685e-04\n",
            "Epoch 35/200\n",
            "2941/2941 [==============================] - 0s 131us/sample - loss: 0.0030 - mse: 0.0030 - val_loss: 3.2290e-04 - val_mse: 3.2290e-04\n",
            "Epoch 36/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0028 - mse: 0.0028 - val_loss: 4.7967e-04 - val_mse: 4.7967e-04\n",
            "Epoch 37/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0030 - mse: 0.0030 - val_loss: 3.7374e-04 - val_mse: 3.7374e-04\n",
            "Epoch 38/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0030 - mse: 0.0030 - val_loss: 4.6405e-04 - val_mse: 4.6405e-04\n",
            "Epoch 39/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0027 - mse: 0.0027 - val_loss: 4.0495e-04 - val_mse: 4.0495e-04\n",
            "Epoch 40/200\n",
            "2941/2941 [==============================] - 0s 143us/sample - loss: 0.0029 - mse: 0.0029 - val_loss: 3.4811e-04 - val_mse: 3.4811e-04\n",
            "Epoch 41/200\n",
            "2941/2941 [==============================] - 0s 146us/sample - loss: 0.0027 - mse: 0.0027 - val_loss: 3.2396e-04 - val_mse: 3.2396e-04\n",
            "Epoch 42/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 2.6931e-04 - val_mse: 2.6931e-04\n",
            "Epoch 43/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0030 - mse: 0.0030 - val_loss: 2.4678e-04 - val_mse: 2.4678e-04\n",
            "Epoch 44/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 7.6046e-04 - val_mse: 7.6046e-04\n",
            "Epoch 45/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0027 - mse: 0.0027 - val_loss: 2.2225e-04 - val_mse: 2.2225e-04\n",
            "Epoch 46/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0027 - mse: 0.0027 - val_loss: 9.4490e-04 - val_mse: 9.4490e-04\n",
            "Epoch 47/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0027 - mse: 0.0027 - val_loss: 2.6059e-04 - val_mse: 2.6059e-04\n",
            "Epoch 48/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0027 - mse: 0.0027 - val_loss: 5.0239e-04 - val_mse: 5.0239e-04\n",
            "Epoch 49/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0027 - mse: 0.0027 - val_loss: 2.4786e-04 - val_mse: 2.4786e-04\n",
            "Epoch 50/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0027 - mse: 0.0027 - val_loss: 4.9303e-04 - val_mse: 4.9303e-04\n",
            "Epoch 51/200\n",
            "2941/2941 [==============================] - 0s 142us/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 3.8579e-04 - val_mse: 3.8579e-04\n",
            "Epoch 52/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 3.1799e-04 - val_mse: 3.1799e-04\n",
            "Epoch 53/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 2.4880e-04 - val_mse: 2.4880e-04\n",
            "Epoch 54/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 2.9584e-04 - val_mse: 2.9584e-04\n",
            "Epoch 55/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 2.0401e-04 - val_mse: 2.0401e-04\n",
            "Epoch 56/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0027 - mse: 0.0027 - val_loss: 6.8894e-04 - val_mse: 6.8894e-04\n",
            "Epoch 57/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 3.4378e-04 - val_mse: 3.4378e-04\n",
            "Epoch 58/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0027 - mse: 0.0027 - val_loss: 3.0759e-04 - val_mse: 3.0759e-04\n",
            "Epoch 59/200\n",
            "2941/2941 [==============================] - 0s 132us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 3.4058e-04 - val_mse: 3.4058e-04\n",
            "Epoch 60/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 7.7397e-04 - val_mse: 7.7397e-04\n",
            "Epoch 61/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0027 - mse: 0.0027 - val_loss: 2.7296e-04 - val_mse: 2.7296e-04\n",
            "Epoch 62/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 4.1173e-04 - val_mse: 4.1173e-04\n",
            "Epoch 63/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 1.8820e-04 - val_mse: 1.8820e-04\n",
            "Epoch 64/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 3.0269e-04 - val_mse: 3.0269e-04\n",
            "Epoch 65/200\n",
            "2941/2941 [==============================] - 0s 143us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 1.4331e-04 - val_mse: 1.4331e-04\n",
            "Epoch 66/200\n",
            "2941/2941 [==============================] - 0s 143us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 2.4633e-04 - val_mse: 2.4633e-04\n",
            "Epoch 67/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 2.0464e-04 - val_mse: 2.0464e-04\n",
            "Epoch 68/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 1.5868e-04 - val_mse: 1.5868e-04\n",
            "Epoch 69/200\n",
            "2941/2941 [==============================] - 0s 132us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 1.7269e-04 - val_mse: 1.7269e-04\n",
            "Epoch 70/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 4.2932e-04 - val_mse: 4.2932e-04\n",
            "Epoch 71/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 4.4202e-04 - val_mse: 4.4202e-04\n",
            "Epoch 72/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 6.6672e-04 - val_mse: 6.6672e-04\n",
            "Epoch 73/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 2.6629e-04 - val_mse: 2.6629e-04\n",
            "Epoch 74/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 3.7629e-04 - val_mse: 3.7629e-04\n",
            "Epoch 75/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 1.5051e-04 - val_mse: 1.5051e-04\n",
            "Epoch 76/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 1.7475e-04 - val_mse: 1.7475e-04\n",
            "Epoch 77/200\n",
            "2941/2941 [==============================] - 0s 143us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.5728e-04 - val_mse: 2.5728e-04\n",
            "Epoch 78/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.7693e-04 - val_mse: 2.7693e-04\n",
            "Epoch 79/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.4833e-04 - val_mse: 2.4833e-04\n",
            "Epoch 80/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.4011e-04 - val_mse: 2.4011e-04\n",
            "Epoch 81/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.8253e-04 - val_mse: 2.8253e-04\n",
            "Epoch 82/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 2.7915e-04 - val_mse: 2.7915e-04\n",
            "Epoch 83/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 6.8403e-04 - val_mse: 6.8403e-04\n",
            "Epoch 84/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 3.3153e-04 - val_mse: 3.3153e-04\n",
            "Epoch 85/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 3.2202e-04 - val_mse: 3.2202e-04\n",
            "Epoch 86/200\n",
            "2941/2941 [==============================] - 0s 132us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 1.7947e-04 - val_mse: 1.7947e-04\n",
            "Epoch 87/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 3.6497e-04 - val_mse: 3.6497e-04\n",
            "Epoch 88/200\n",
            "2941/2941 [==============================] - 0s 141us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 1.8172e-04 - val_mse: 1.8172e-04\n",
            "Epoch 89/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 3.2181e-04 - val_mse: 3.2181e-04\n",
            "Epoch 90/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 7.9180e-04 - val_mse: 7.9180e-04\n",
            "Epoch 91/200\n",
            "2941/2941 [==============================] - 0s 144us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.4354e-04 - val_mse: 2.4354e-04\n",
            "Epoch 92/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 3.7164e-04 - val_mse: 3.7164e-04\n",
            "Epoch 93/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 94/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 2.2118e-04 - val_mse: 2.2118e-04\n",
            "Epoch 95/200\n",
            "2941/2941 [==============================] - 0s 132us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 4.3960e-04 - val_mse: 4.3960e-04\n",
            "Epoch 96/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.6423e-04 - val_mse: 2.6423e-04\n",
            "Epoch 97/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 5.0497e-04 - val_mse: 5.0497e-04\n",
            "Epoch 98/200\n",
            "2941/2941 [==============================] - 0s 132us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 3.4827e-04 - val_mse: 3.4827e-04\n",
            "Epoch 99/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 2.5957e-04 - val_mse: 2.5957e-04\n",
            "Epoch 100/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 4.9954e-04 - val_mse: 4.9954e-04\n",
            "Epoch 101/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 4.4547e-04 - val_mse: 4.4547e-04\n",
            "Epoch 102/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 2.0575e-04 - val_mse: 2.0575e-04\n",
            "Epoch 103/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.8983e-04 - val_mse: 2.8983e-04\n",
            "Epoch 104/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 3.3862e-04 - val_mse: 3.3862e-04\n",
            "Epoch 105/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 3.6139e-04 - val_mse: 3.6139e-04\n",
            "Epoch 106/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 3.4299e-04 - val_mse: 3.4299e-04\n",
            "Epoch 107/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0025 - mse: 0.0025 - val_loss: 2.0575e-04 - val_mse: 2.0575e-04\n",
            "Epoch 108/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.0002e-04 - val_mse: 2.0002e-04\n",
            "Epoch 109/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 3.9509e-04 - val_mse: 3.9509e-04\n",
            "Epoch 110/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 3.5516e-04 - val_mse: 3.5516e-04\n",
            "Epoch 111/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 6.2773e-04 - val_mse: 6.2773e-04\n",
            "Epoch 112/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 3.2961e-04 - val_mse: 3.2961e-04\n",
            "Epoch 113/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 5.0306e-04 - val_mse: 5.0306e-04\n",
            "Epoch 114/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.7500e-04 - val_mse: 2.7500e-04\n",
            "Epoch 115/200\n",
            "2941/2941 [==============================] - 0s 141us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.0775e-04 - val_mse: 2.0775e-04\n",
            "Epoch 116/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 1.7315e-04 - val_mse: 1.7315e-04\n",
            "Epoch 117/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.9961e-04 - val_mse: 2.9961e-04\n",
            "Epoch 118/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 2.7254e-04 - val_mse: 2.7254e-04\n",
            "Epoch 119/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 1.8574e-04 - val_mse: 1.8574e-04\n",
            "Epoch 120/200\n",
            "2941/2941 [==============================] - 0s 148us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 1.3545e-04 - val_mse: 1.3545e-04\n",
            "Epoch 121/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.2772e-04 - val_mse: 2.2772e-04\n",
            "Epoch 122/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.0516e-04 - val_mse: 2.0516e-04\n",
            "Epoch 123/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 1.7892e-04 - val_mse: 1.7892e-04\n",
            "Epoch 124/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 7.9027e-04 - val_mse: 7.9027e-04\n",
            "Epoch 125/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 2.9171e-04 - val_mse: 2.9171e-04\n",
            "Epoch 126/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 2.1293e-04 - val_mse: 2.1293e-04\n",
            "Epoch 127/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0019 - mse: 0.0019 - val_loss: 2.3049e-04 - val_mse: 2.3049e-04\n",
            "Epoch 128/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 1.6249e-04 - val_mse: 1.6249e-04\n",
            "Epoch 129/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 1.9115e-04 - val_mse: 1.9115e-04\n",
            "Epoch 130/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.7404e-04 - val_mse: 2.7404e-04\n",
            "Epoch 131/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 1.4205e-04 - val_mse: 1.4205e-04\n",
            "Epoch 132/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 1.8448e-04 - val_mse: 1.8448e-04\n",
            "Epoch 133/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0020 - mse: 0.0020 - val_loss: 1.7395e-04 - val_mse: 1.7395e-04\n",
            "Epoch 134/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 7.5417e-04 - val_mse: 7.5417e-04\n",
            "Epoch 135/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.8233e-04 - val_mse: 2.8233e-04\n",
            "Epoch 136/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 1.9968e-04 - val_mse: 1.9968e-04\n",
            "Epoch 137/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.9373e-04 - val_mse: 2.9373e-04\n",
            "Epoch 138/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 3.0658e-04 - val_mse: 3.0658e-04\n",
            "Epoch 139/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.8305e-04 - val_mse: 2.8305e-04\n",
            "Epoch 140/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 1.7062e-04 - val_mse: 1.7062e-04\n",
            "Epoch 141/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 2.1635e-04 - val_mse: 2.1635e-04\n",
            "Epoch 142/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 4.9017e-04 - val_mse: 4.9017e-04\n",
            "Epoch 143/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 4.6040e-04 - val_mse: 4.6040e-04\n",
            "Epoch 144/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 4.4136e-04 - val_mse: 4.4136e-04\n",
            "Epoch 145/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.1064e-04 - val_mse: 2.1064e-04\n",
            "Epoch 146/200\n",
            "2941/2941 [==============================] - 0s 150us/sample - loss: 0.0020 - mse: 0.0020 - val_loss: 2.3887e-04 - val_mse: 2.3887e-04\n",
            "Epoch 147/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 3.0271e-04 - val_mse: 3.0271e-04\n",
            "Epoch 148/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 5.5932e-04 - val_mse: 5.5932e-04\n",
            "Epoch 149/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 3.7344e-04 - val_mse: 3.7344e-04\n",
            "Epoch 150/200\n",
            "2941/2941 [==============================] - 0s 130us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 2.4043e-04 - val_mse: 2.4043e-04\n",
            "Epoch 151/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 3.2186e-04 - val_mse: 3.2186e-04\n",
            "Epoch 152/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 2.2212e-04 - val_mse: 2.2212e-04\n",
            "Epoch 153/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 4.5164e-04 - val_mse: 4.5164e-04\n",
            "Epoch 154/200\n",
            "2941/2941 [==============================] - 0s 143us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 3.0866e-04 - val_mse: 3.0866e-04\n",
            "Epoch 155/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 4.3859e-04 - val_mse: 4.3859e-04\n",
            "Epoch 156/200\n",
            "2941/2941 [==============================] - 0s 142us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 1.7722e-04 - val_mse: 1.7722e-04\n",
            "Epoch 157/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 1.4205e-04 - val_mse: 1.4205e-04\n",
            "Epoch 158/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 3.8573e-04 - val_mse: 3.8573e-04\n",
            "Epoch 159/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 5.1227e-04 - val_mse: 5.1227e-04\n",
            "Epoch 160/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 6.0401e-04 - val_mse: 6.0401e-04\n",
            "Epoch 161/200\n",
            "2941/2941 [==============================] - 0s 142us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.2404e-04 - val_mse: 2.2404e-04\n",
            "Epoch 162/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 2.0785e-04 - val_mse: 2.0785e-04\n",
            "Epoch 163/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0020 - mse: 0.0020 - val_loss: 1.3461e-04 - val_mse: 1.3461e-04\n",
            "Epoch 164/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.8628e-04 - val_mse: 2.8628e-04\n",
            "Epoch 165/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 3.6345e-04 - val_mse: 3.6345e-04\n",
            "Epoch 166/200\n",
            "2941/2941 [==============================] - 0s 145us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 2.2402e-04 - val_mse: 2.2402e-04\n",
            "Epoch 167/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 5.8335e-04 - val_mse: 5.8335e-04\n",
            "Epoch 168/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.2372e-04 - val_mse: 2.2372e-04\n",
            "Epoch 169/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 1.4121e-04 - val_mse: 1.4121e-04\n",
            "Epoch 170/200\n",
            "2941/2941 [==============================] - 0s 131us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 1.7878e-04 - val_mse: 1.7878e-04\n",
            "Epoch 171/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.0531e-04 - val_mse: 2.0531e-04\n",
            "Epoch 172/200\n",
            "2941/2941 [==============================] - 0s 144us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.1014e-04 - val_mse: 2.1014e-04\n",
            "Epoch 173/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 3.3652e-04 - val_mse: 3.3652e-04\n",
            "Epoch 174/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.5610e-04 - val_mse: 2.5610e-04\n",
            "Epoch 175/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 2.0226e-04 - val_mse: 2.0226e-04\n",
            "Epoch 176/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0020 - mse: 0.0020 - val_loss: 2.2027e-04 - val_mse: 2.2027e-04\n",
            "Epoch 177/200\n",
            "2941/2941 [==============================] - 0s 132us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.6599e-04 - val_mse: 2.6599e-04\n",
            "Epoch 178/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.8211e-04 - val_mse: 2.8211e-04\n",
            "Epoch 179/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 3.4024e-04 - val_mse: 3.4024e-04\n",
            "Epoch 180/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.2552e-04 - val_mse: 2.2552e-04\n",
            "Epoch 181/200\n",
            "2941/2941 [==============================] - 0s 134us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 2.7498e-04 - val_mse: 2.7498e-04\n",
            "Epoch 182/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0020 - mse: 0.0020 - val_loss: 1.2155e-04 - val_mse: 1.2155e-04\n",
            "Epoch 183/200\n",
            "2941/2941 [==============================] - 0s 142us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 3.0305e-04 - val_mse: 3.0305e-04\n",
            "Epoch 184/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0020 - mse: 0.0020 - val_loss: 1.7051e-04 - val_mse: 1.7051e-04\n",
            "Epoch 185/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 2.1874e-04 - val_mse: 2.1874e-04\n",
            "Epoch 186/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.7259e-04 - val_mse: 2.7259e-04\n",
            "Epoch 187/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 4.4053e-04 - val_mse: 4.4053e-04\n",
            "Epoch 188/200\n",
            "2941/2941 [==============================] - 0s 137us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 2.3014e-04 - val_mse: 2.3014e-04\n",
            "Epoch 189/200\n",
            "2941/2941 [==============================] - 0s 136us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 1.4569e-04 - val_mse: 1.4569e-04\n",
            "Epoch 190/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0020 - mse: 0.0020 - val_loss: 2.2581e-04 - val_mse: 2.2581e-04\n",
            "Epoch 191/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 5.6154e-04 - val_mse: 5.6154e-04\n",
            "Epoch 192/200\n",
            "2941/2941 [==============================] - 0s 140us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 1.5896e-04 - val_mse: 1.5896e-04\n",
            "Epoch 193/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 3.4289e-04 - val_mse: 3.4289e-04\n",
            "Epoch 194/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.4880e-04 - val_mse: 2.4880e-04\n",
            "Epoch 195/200\n",
            "2941/2941 [==============================] - 0s 138us/sample - loss: 0.0024 - mse: 0.0024 - val_loss: 2.1759e-04 - val_mse: 2.1759e-04\n",
            "Epoch 196/200\n",
            "2941/2941 [==============================] - 0s 133us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 1.7141e-04 - val_mse: 1.7141e-04\n",
            "Epoch 197/200\n",
            "2941/2941 [==============================] - 0s 147us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 2.9095e-04 - val_mse: 2.9095e-04\n",
            "Epoch 198/200\n",
            "2941/2941 [==============================] - 0s 135us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 3.2057e-04 - val_mse: 3.2057e-04\n",
            "Epoch 199/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0022 - mse: 0.0022 - val_loss: 1.5267e-04 - val_mse: 1.5267e-04\n",
            "Epoch 200/200\n",
            "2941/2941 [==============================] - 0s 139us/sample - loss: 0.0021 - mse: 0.0021 - val_loss: 1.9727e-04 - val_mse: 1.9727e-04\n",
            "mse score on 5 percent data: 0.4860180428936668\n",
            "mae score on 5 percent data: 0.22173995874089977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1frVXMM-hvd",
        "colab_type": "text"
      },
      "source": [
        "NOW TO PREDICT FOR 16 AUG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_ABdGU5UqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_scores = model.predict(test)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIDqzJ_0YXEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.DataFrame()\n",
        "sub['Stock Index']=test_indx\n",
        "sub['Put-Call Ratio'] = y_scores"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc4LgL3fZFwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "846ddb9f-1e80-40f0-becd-1c14686d87a1"
      },
      "source": [
        "print(sub.head())\n",
        "sub.to_csv('/content/drive/My Drive/hack/task2_outputs/gru_16AUG.csv',index=False)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Stock Index  Put-Call Ratio\n",
            "1      AC3235        0.951753\n",
            "2      AC3236        1.112391\n",
            "3      AC3237        1.251455\n",
            "4      AC3238        1.696231\n",
            "5      AC3239        1.906235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQH_HIBYB84b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}